<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">TIA</journal-id>
<journal-id journal-id-type="hwp">sptia</journal-id>
<journal-id journal-id-type="nlm-ta">Trends Amplif</journal-id>
<journal-title>Trends in Amplification</journal-title>
<issn pub-type="ppub">1084-7138</issn>
<issn pub-type="epub">1940-5588</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/1084713812471906</article-id>
<article-id pub-id-type="publisher-id">10.1177_1084713812471906</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Analog-to-Digital Conversion to Accommodate the Dynamics of Live Music in Hearing Instruments</article-title>
</title-group>
<contrib-group content-type="issue">
<contrib contrib-type="guest-editor">
<name><surname>Chasin</surname><given-names>Marshall</given-names></name>
<degrees>AuD</degrees>
</contrib>
<contrib contrib-type="guest-editor">
<name><surname>Hockley</surname><given-names>Neil</given-names></name>
<degrees>MSc</degrees>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Hockley</surname><given-names>Neil S.</given-names></name>
<degrees>MSc</degrees>
<xref ref-type="aff" rid="aff1-1084713812471906">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Bahlmann</surname><given-names>Frauke</given-names></name>
<degrees>Dipl.-Ing. (FH)</degrees>
<xref ref-type="aff" rid="aff1-1084713812471906">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Fulton</surname><given-names>Bernadette</given-names></name>
<degrees>BA, DipAud.</degrees>
<xref ref-type="aff" rid="aff1-1084713812471906">1</xref>
</contrib>
</contrib-group>
<aff id="aff1-1084713812471906"><label>1</label>Bernafon AG, Berne, Switzerland</aff>
<author-notes>
<corresp id="corresp1-1084713812471906">Neil S. Hockley, Bernafon AG, Morgenstrasse 131, 3018 Berne, Switzerland Email: <email>nh@bernafon.ch</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>9</month>
<year>2012</year>
</pub-date>
<volume>16</volume>
<issue>3</issue>
<issue-title>Special Issue on Music and Hearing Loss: Preventative and Rehabilitative options</issue-title>
<fpage>146</fpage>
<lpage>158</lpage>
<permissions>
<copyright-statement>© The Author(s) 2012</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="sage">SAGE Publications</copyright-holder>
</permissions>
<abstract>
<p>Hearing instrument design focuses on the amplification of speech to reduce the negative effects of hearing loss. Many amateur and professional musicians, along with music enthusiasts, also require their hearing instruments to perform well when listening to the frequent, high amplitude peaks of live music. One limitation, in most current digital hearing instruments with 16-bit analog-to-digital (A/D) converters, is that the compressor before the A/D conversion is limited to 95 dB (SPL) or less at the input. This is more than adequate for the dynamic range of speech; however, this does not accommodate the amplitude peaks present in live music. The hearing instrument input compression system can be adjusted to accommodate for the amplitudes present in music that would otherwise be compressed before the A/D converter in the hearing instrument. The methodology behind this technological approach will be presented along with measurements to demonstrate its effectiveness.</p>
</abstract>
<kwd-group>
<kwd>hearing aids</kwd>
<kwd>hearing instruments</kwd>
<kwd>live music</kwd>
<kwd>musicians and hearing loss A/D conversion peak sound pressure level of music</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="section1-1084713812471906" sec-type="intro">
<title>Introduction</title>
<p>Hearing instruments are designed and have been shown to reduce the negative effects of hearing loss (<xref ref-type="bibr" rid="bibr12-1084713812471906">Chisolm et al., 2007</xref>; <xref ref-type="bibr" rid="bibr48-1084713812471906">National Council on the Aging [NCOA], 1999</xref>). <xref ref-type="bibr" rid="bibr12-1084713812471906">Chisolm et al. (2007)</xref> describe hearing instrument use as being a relatively noninvasive, low-risk option for hearing impaired people with many potential benefits. They go on to describe hearing instruments as the only easily accessible treatment for hearing loss, which improves the health-related quality of life in adults by reducing the psychological, social, and emotional effects of sensorineural hearing loss. To address these quality of life issues, hearing instruments are designed to amplify speech signals well, and this is an important key driver behind their development. There is a wide area of research designed to define the characteristics of speech and to subsequently develop amplification schemes in terms of audibility and comfort (<xref ref-type="bibr" rid="bibr3-1084713812471906">American National Standards Institute, 1997</xref>; <xref ref-type="bibr" rid="bibr6-1084713812471906">Byrne et al., 1994</xref>; <xref ref-type="bibr" rid="bibr34-1084713812471906">Keidser, Dillon, Flax, Ching, &amp; Brewer, 2011</xref>; <xref ref-type="bibr" rid="bibr46-1084713812471906">Moore, Glasberg, &amp; Stone, 2010</xref>; <xref ref-type="bibr" rid="bibr59-1084713812471906">Scollie et al., 2005</xref>). There are, however, hearing instrument users and potential users who require their hearing instruments to amplify live music well, especially with regard to the dynamic characteristics of live music (<xref ref-type="bibr" rid="bibr38-1084713812471906">Killion, 2009</xref>; <xref ref-type="bibr" rid="bibr54-1084713812471906">Revit, 2009</xref>). These individuals may be professional or amateur musicians or even enthusiastic concert goers. Music, for some individuals, can be considered to be a necessity to enhance their quality of life and at least their feelings of well-being (<xref ref-type="bibr" rid="bibr41-1084713812471906">Levitin, 2006</xref>; <xref ref-type="bibr" rid="bibr44-1084713812471906">Menon &amp; Levitin, 2005</xref>; <xref ref-type="bibr" rid="bibr70-1084713812471906">Zatorre, 2005</xref>). The following article will examine some key considerations in adapting speech-based amplification schemes to meet the needs of hearing instrument users who listen to music. This will include a discussion of the dynamic characteristics of speech and music, along with a discussion of some limitations of signal processing that arise during the conversion of music from the analog to the digital domains.</p>
</sec>
<sec id="section2-1084713812471906">
<title>The Dynamic Characteristics of Speech and Music</title>
<p>Why do hearing instruments typically fail when it comes to reproducing the dynamics of live music? Speech has a well-defined relationship between loudness (the psychological impression of the intensity of a sound) and intensity (the physical quantity relating to the magnitude or amount of sound). For music, this relationship is highly variable and greatly depends on the musical instrument being played (<xref ref-type="bibr" rid="bibr8-1084713812471906">Chasin, 2006a</xref>; <xref ref-type="bibr" rid="bibr22-1084713812471906">Fabiani &amp; Friberg, 2011</xref>). Speech has many acoustic differences to music regardless of genre, as has been described previously in the literature (<xref ref-type="bibr" rid="bibr7-1084713812471906">Chasin, 2003</xref>; <xref ref-type="bibr" rid="bibr11-1084713812471906">Chasin &amp; Russo, 2004</xref>). The dynamic characteristics of music create a challenge to the current generation of digital hearing instruments. Many multimemory digital hearing instruments that are available today have music programs. But little is different from other standard speech-specific programs and so the musician cannot experience a natural perception of the dynamics of live music (<xref ref-type="bibr" rid="bibr7-1084713812471906">Chasin, 2003</xref>; <xref ref-type="bibr" rid="bibr68-1084713812471906">Zakis &amp; Fulton, 2009</xref>).</p>
<p>While clinicians have frequently relied on software fine-tuning to improve the sound quality of music reproduction in digital hearing instruments, the result falls short of what is required because there are many limiting factors that are inherent to the device itself (<xref ref-type="bibr" rid="bibr10-1084713812471906">Chasin, 2010</xref>). Such factors might include the quality of miniature transducers, the bandwidth or frequency response of the device, and the dynamic range available in the device. In the past, the transducers used in hearing instruments were frequently blamed for poor fidelity for music. However, this has been shown repeatedly not to be the case (<xref ref-type="bibr" rid="bibr35-1084713812471906">Killion, 1988</xref>) and the technology has continued to improve. Extended bandwidth in hearing instruments has also assisted in addressing the mismatch between the frequency response of a hearing instrument (now reported up to 10000Hz) and the frequencies represented in live music (up to 20000Hz). Where sensorineural hearing loss is present, the benefit of extended high frequencies in the hearing instrument will depend on the residual hearing of the user and, in many cases, this will be significantly limited (<xref ref-type="bibr" rid="bibr55-1084713812471906">Ricketts, Dittberner, &amp; Johnson, 2008</xref>). Dynamic range, on the other hand, is the factor inherent to hearing instruments with potential for improvement. Although hearing instrument transducers can easily handle the demands of the dynamic range in music, typically these capabilities are not utilized.</p>
<p>One key difference between speech and music is the difference in intensity. Soft speech is generally considered as having a long-term RMS level of 50 dB SPL, conversational speech of 65 dB SPL, and loud speech of 80 dB SPL.<sup><xref ref-type="fn" rid="fn1-1084713812471906">1</xref></sup> These input classifications are used to show the amplification response typically seen when measured with a commercially available probe-microphone real ear measurement system, or when simulated by a hearing instrument manufacturer’s software. While there are many different individual variations in the levels of speech, even shouted male speech does not usually exceed 89 dB SPL (<xref ref-type="bibr" rid="bibr49-1084713812471906">Olsen, 1998</xref>). Music, on the other hand, is quite different and can easily reach 105 dB (A) and can have peaks of 120 dB (A) or even higher (<xref ref-type="bibr" rid="bibr38-1084713812471906">Killion, 2009</xref>; <xref ref-type="bibr" rid="bibr50-1084713812471906">Pawlaczyk-Luszczynska, Dudarewicz, Zamoijska, &amp; Sliwinska-Kowalska, 2010</xref>). For example, <xref ref-type="bibr" rid="bibr38-1084713812471906">Killion (2009)</xref> measured the peaks of a symphony orchestra in a concert hall at 114 to 116 dB (C), while <xref ref-type="bibr" rid="bibr23-1084713812471906">Flugrath (1969)</xref> measured amplified rock music with levels of 114 dB (A). It must be noted that these peaks, especially for orchestral music, are very short in duration and are typically higher than the exposure levels that instrumentalists are subjected to on a long-term basis (<xref ref-type="bibr" rid="bibr4-1084713812471906">Behar, Wong, &amp; Kunov, 2006</xref>; <xref ref-type="bibr" rid="bibr43-1084713812471906">MacDonald, Behar, Wong, &amp; Kunov, 2008</xref>; <xref ref-type="bibr" rid="bibr51-1084713812471906">Phillips &amp; Mace, 2008</xref>; <xref ref-type="bibr" rid="bibr52-1084713812471906">Poissant, Freyman, MacDonald, &amp; Nunes, 2012</xref>; <xref ref-type="bibr" rid="bibr56-1084713812471906">Royster, Royster, &amp; Killion, 1991</xref>). Amplified rock music, however, can typically have a long-term average level that is higher than that for orchestral music (<xref ref-type="bibr" rid="bibr13-1084713812471906">Clark, 1991</xref>).</p>
<p>Typically, a digital hearing instrument compresses the peaks of the signal once they reach 95 dB SPL before the A/D conversion. This is based on the 16-bit analog-to-digital A/D conversion architecture that is employed by most of the hearing instruments currently in use (<xref ref-type="bibr" rid="bibr2-1084713812471906">Agnew, 2002</xref>; <xref ref-type="bibr" rid="bibr21-1084713812471906">Edwards, 2007</xref>; <xref ref-type="bibr" rid="bibr30-1084713812471906">Hamacher et al., 2005</xref>). A compression threshold of 95 dB before the A/D converter is more than adequate even for loud speech, even when the level is measured close to the speaker’s lips. <xref ref-type="bibr" rid="bibr25-1084713812471906">French and Steinberg (1947)</xref> found levels of 90 dB SPL, 5.1 cm (2 in.) from the speaker’s lips. Average overall levels are lower as was previously mentioned but this can vary depending on the measurement technique (<xref ref-type="bibr" rid="bibr5-1084713812471906">Byrne, 1977</xref>; <xref ref-type="bibr" rid="bibr14-1084713812471906">Cornelisse, Gagné, &amp; Seewald, 1991</xref>; <xref ref-type="bibr" rid="bibr20-1084713812471906">Dunn &amp; White, 1940</xref>; <xref ref-type="bibr" rid="bibr25-1084713812471906">French &amp; Steinberg, 1947</xref>; <xref ref-type="bibr" rid="bibr40-1084713812471906">Ladefoged &amp; McKinney, 1963</xref>; <xref ref-type="bibr" rid="bibr49-1084713812471906">Olsen; 1998</xref>) For the peaks of live music, this compression threshold of 95dB at the input is too low and the music can sound compressed, unnatural, and even slightly distorted. Compression is used widely in the recording industry to make music sound “louder” and also to make it easier for data reduction for storage on portable devices but is not generally preferred by normal hearing listeners when they are given the choice (<xref ref-type="bibr" rid="bibr16-1084713812471906">Croghan, Arehart, &amp; Kates, 2012</xref>). So could the use of low compression thresholds before the A/D converter in hearing instruments be thought of being analogous to the experience of normal hearing individuals when listening to low bit rate encoded music files? This question could be investigated in future studies.</p>
<p>There is nothing that can be done via the hearing instrument software to correct or reduce the effects of this low input compression threshold on the signal. The resulting perceptual distortions are especially a drawback for musicians in ensembles, who may be trying to hear their fellow musicians to play correctly. We will discuss a digital signal processing methodology that can adapt the speech-specific compression limiting at the input to the A/D converter to a music-specific configuration, along with measurements to demonstrate its effectiveness.</p>
</sec>
<sec id="section3-1084713812471906">
<title>A/D Conversion to Accommodate the Dynamics of Live Music</title>
<sec id="section4-1084713812471906">
<title>The Fundamentals of A/D Conversion</title>
<p>A/D conversion is part of the front end of the digital hearing instrument. It is comprised of an input source, primarily the hearing instrument microphone, and the A/D converter (<xref ref-type="bibr" rid="bibr17-1084713812471906">Csermak &amp; Armstrong, 1999</xref>). A detailed discussion of the process of A/D conversion is beyond the scope of this article; however, a short discussion about it helps to explain the potential solution to this issue. The key element of A/D conversion involved with dynamic range is quantization, which classifies the amplitude information of a signal (<xref ref-type="bibr" rid="bibr2-1084713812471906">Agnew, 2002</xref>). To briefly explain quantization, it is necessary to look at some basic definitions. A bit (binary digit) is represented as either a 1 or a 0 and is the smallest possible piece of digital information (<xref ref-type="bibr" rid="bibr1-1084713812471906">Agnew, 2000</xref>). The digital word length refers to the number of bits that are used to represent a signal. Therefore, a 16-bit digital word could look like this—1010111001100111. Without focusing on a specific implementation, the quantization step size is generally defined as 2<sup>digital word length</sup> (<xref ref-type="bibr" rid="bibr2-1084713812471906">Agnew, 2002</xref>). <xref ref-type="fig" rid="fig1-1084713812471906">Figure 1</xref> shows the dependency of quantization and resolution. The gray curve is part of a sine signal normalized to +/– 0.9 and the black line represent the discrete quantization steps.</p>
<fig id="fig1-1084713812471906" position="float">
<label>Figure 1.</label>
<caption>
<p>Quantization steps for a portion of a simple waveform</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig1.tif"/></fig>
<p>An eight-bit quantization creates 2<sup>8</sup> or 256 discrete levels to represent the amplitude of a signal as schematically shown on the left side, whereas a 16-bit quantization, shown on the right, will create 2<sup>16</sup> discrete levels or 65536 levels. The more quantization levels, the more accurate the resolution is for defining the amplitude. Each bit in a digital system represents approximately 6 dB of dynamic range (<xref ref-type="bibr" rid="bibr58-1084713812471906">Ryan &amp; Tewari, 2009</xref>). Following this rule, <xref ref-type="table" rid="table1-1084713812471906">Table 1</xref> shows the relationship between digital word length and dynamic range.</p>
<table-wrap id="table1-1084713812471906" position="float">
<label>Table 1.</label>
<caption>
<p>The Relationship Between Digital Word Length and Dynamic Range</p>
</caption>
<graphic alternate-form-of="table1-1084713812471906" xlink:href="10.1177_1084713812471906-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Digital word length</th>
<th align="center">Dynamic range</th>
</tr>
</thead>
<tbody>
<tr>
<td>12 bit * 6 dB</td>
<td>–&gt;72 dB</td>
</tr>
<tr>
<td>16 bit * 6 dB</td>
<td>–&gt;96 dB</td>
</tr>
<tr>
<td>20 bit * 6 dB</td>
<td>–&gt;120 dB</td>
</tr>
<tr>
<td>24 bit * 6 dB</td>
<td>–&gt;144 dB</td>
</tr>
<tr>
<td/>
<td>2<sup>24</sup> = 16777216 discrete steps</td>
</tr>
</tbody>
</table></table-wrap>
<p>Most current hearing instruments use 16-bit A/D conversion. However, depending on the hearing instrument design, even if a digital system uses 16-bit A/D conversion, the dynamic range may in fact be limited to only 12 bits, for example, due to other requirements, such as the directional microphone and feedback cancellation processing systems (<xref ref-type="bibr" rid="bibr1-1084713812471906">Agnew, 2000</xref>). The result is that to accommodate the peaks of live music, this can only be truly represented by a digital hearing instrument system using A/D conversion of at least 20-bit word lengths resulting in a potential dynamic range of 120 dB.</p>
<p>In addition to the representation of the dynamic range of a signal when converting a signal from analog to digital, it is also important to be aware of quantization error (<xref ref-type="bibr" rid="bibr42-1084713812471906">Lyons, 2004</xref>). A large number of discrete steps might not offer infinite precision in the representation of the amplitude because of the quantization error. Due to the fact that the quantization process will always be rounded up or rounded down to the nearest level that is available (<xref ref-type="bibr" rid="bibr1-1084713812471906">Agnew, 2000</xref>), the result is that there may be a difference between the actual signal and the quantized signal. This error can produce audible noise, which may be masked by the microphone noise in the hearing instrument. An increase in the number of available quantization levels can be made by increasing the digital word length and this will decrease the quantization error (<xref ref-type="bibr" rid="bibr2-1084713812471906">Agnew, 2002</xref>). This enables the digital representation of the analog signal to be more accurate; however, it requires an increase in the power supply to the hearing instrument. To preserve battery life, compromises must be made in the design of the digital hearing instrument. The question remains as to what can be done to improve current digital hearing instrument systems that use 16-bit A/D converters.</p>
</sec>
<sec id="section5-1084713812471906">
<title>Overcoming the Current Limitations of Dynamic Range</title>
<p>Hearing instrument integrated circuits need to be efficient with regard to battery drain and so adjusting the digital word length to accommodate speech while minimizing battery drain is very important. This is one of the main reasons why 20- or even 24-bit A/D conversion is not widely seen in hearing instruments that are currently available today (<xref ref-type="bibr" rid="bibr33-1084713812471906">Kates, 2008</xref>). This may, however, change in the future as technology changes. Until then, is there anything that can be done within the hearing instrument, before input compression, to be able to handle the loud peaks of music with 16-bit digital architecture? The answer lies in using a 16-bit A/D converter but shifting the maximum input level where the hearing instrument works more linearly, so that the AGC<sub>input</sub> (automatic gain control) does not start to compress until the level from the microphone exceeds approximately 110 dB SPL (<xref ref-type="bibr" rid="bibr7-1084713812471906">Chasin, 2003</xref>). This basic idea of modifying the AGC<sub>input</sub> was implemented, in a commercially available hearing instrument, by Bernafon AG in 2010. The result is that most, if not all, of the peaks of loud live music are not compressed before the A/D converter without significantly increasing the battery drain, which has been verified by power consumption investigations. In <xref ref-type="fig" rid="fig2-1084713812471906">Figure 2</xref>, it is possible to see schematically the difference between the shifted (black wave up to 110 dB SPL) and the reference processing (gray wave up to 96 dB SPL) at the front end. Assuming that the gray wave has a sound pressure level of 96 dB SPL, the gray arrow in the AGC<sub>input</sub> controller block indicates the cutoff. Input signals with a higher level will not be converted into the digital domain and processed any further. The black wave represents a signal with the characteristics of live music as described above. The black arrow is now changing the AGC<sub>input</sub> by shifting the dynamic range toward a higher level by using a delta, “Δ.” However, the range between the min and max value of the amplitude stays the same [–1:1-1/2^(word length-1)] and is not extended like the best case solution with a 20-bit system. After the A/D conversion, this “Δ” will be compensated for elsewhere within the signal processing path of the hearing instrument.</p>
<fig id="fig2-1084713812471906" position="float">
<label>Figure 2.</label>
<caption>
<p>A basic block diagram illustrating the signal path of the A/D conversation</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig2.tif"/></fig>
<p>Another way to look at this idea is illustrated in <xref ref-type="fig" rid="fig3-1084713812471906">Figure 3</xref>, where the behavior of the AGC is shown in an in/output diagram. In the reference situation (black line) the threshold of the AGC<sub>input</sub> cuts in at 95 dB SPL, whereas the gray line shows the level-shifted condition that has its threshold at 110 dB SPL because of the implemented attenuation of −15 dB in the AGC<sub>input</sub>. This will subsequently be referred to as the “level-shift.”</p>
<fig id="fig3-1084713812471906" position="float">
<label>Figure 3.</label>
<caption>
<p>Effect of the AGC input/output behavior for a reference (black line) compared to the level-shifted condition (gray line)</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig3.tif"/></fig>
<p>It is very important to emphasize that the level-shift is occurring in the front end, before the amplification within the hearing instrument. The maximum power output (MPO) is therefore not changed. The peaks of music are not increasing the output levels. Short-duration intense sounds in excess of 115 dB SPL create a risk of permanent threshold shift (PTS), as <xref ref-type="bibr" rid="bibr32-1084713812471906">Hunter, Ries, Schlauch, Levine, and Ward (1999)</xref> discussed in their study on acoustic reflex testing. The MPO is always set based on the real or calculated uncomfortable loudness levels (UCL) within the hearing instrument to avoid any potential issues of PTS or even temporary threshold shift (TTS) for the hearing instrument user. The usual care should be taken when setting the MPO regardless of input.</p>
</sec>
</sec>
<sec id="section6-1084713812471906">
<title>Acoustical Measurements With a Modified Input AGC</title>
<p>A series of measurements was conducted to verify the effectiveness of the level-shift within the digital front end of a hearing instrument.</p>
<sec id="section7-1084713812471906">
<title>Method, Equipment, and Setup</title>
<p>All measurements were performed with the same setup. A custom programmed LabVIEW 2010 SP1 (National Instruments Corporation, Austin, Texas) based recording tool was used, which gives the opportunity to do real-time input/output measurements. The chassis from a National Instruments (NI) MPXI-1024 with an embedded controller NI PXI-8108 and the analog signal acquisition and generation card NI PXI-4461 were integrated into the setup as shown in <xref ref-type="fig" rid="fig4-1084713812471906">Figure 4</xref>. The signals were recorded via a Bruel &amp; Kjaer 2cc Coupler 4946 connected to a G.R.A.S. AG 40 microphone with the G.R.A.S. Type 26 A preamplifier and 12 AA power supply. The signals were presented in the free-field via a multichannel power amplifier, RAM Audio T2408, connected to a stand-mounted Bose MA 12 Line Array loud speaker (LS).</p>
<fig id="fig4-1084713812471906" position="float">
<label>Figure 4.</label>
<caption>
<p>Measurement setup</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig4.tif"/></fig>
<p>The hearing instrument was placed on a stand 40 cm away from and pointing toward the middle of the loud speaker. A sound-absorbing curtain covered any reflective surfaces in a 30m<sup>2</sup> quiet room. Two different acoustic stimuli were used. The first consisted of sine signals of 1 kHz and 3 kHz, while the second consisted of a mixture of small recorded excerpts of music, 15 to 30 s in duration, representing different styles and genres of music with broad dynamic changes (e.g., choir and orchestra: Elgar <italic>The Dream of Gerontius</italic>). All signals were normalized to +/– 1 with Adobe Audition 3.0 (Adobe Systems Incorporated, San Jose, California). Recordings were used to control as many variables as possible within the test room and also to ensure the reliability and repeatability of the measurements. An integrated calibration routine ensured that the desired sound level was applied at the calibration point. The hearing instrument used was a commercially available BTE unit, chosen randomly from stock.</p>
<p>Two conditions were compared, first, a reference program with all adaptive features deactivated; and second, the level-shifted program with the modified AGC<sub>input</sub>. For comparison reasons, the gain was set to the same linear values via the fitting software with minimal amplification to isolate the front end of the hearing instrument as much as possible (<xref ref-type="bibr" rid="bibr9-1084713812471906">Chasin, 2006b</xref>), as can be seen in <xref ref-type="fig" rid="fig5-1084713812471906">Figure 5</xref>. The amplification was chosen to be rather small to avoid any interaction with the MPO of the hearing instrument. The expansion system was set to the maximum to overcome the possible side effects of the internal and external noise floors. No other special settings were used.</p>
<fig id="fig5-1084713812471906" position="float">
<label>Figure 5</label>
<caption>
<p>Linear insertion gain simulation of the hearing instrument</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig5.tif"/></fig>
</sec>
<sec id="section8-1084713812471906">
<title>Results</title>
<p>An easy way to see the difference between the preamplification of the reference and level-shifted conditions is by looking at an input/output function. In <xref ref-type="fig" rid="fig6-1084713812471906">Figure 6</xref>, we can see an input/output function for a 1000Hz sine signal with the gain setting shown in <xref ref-type="fig" rid="fig5-1084713812471906">Figure 5</xref>. The gray line represents the reference program designed for speech with a 95 dB SPL cutoff. After the 95 dB SPL input, the curve begins to level off, indicating that the instrument is compressing this signal. The black line represents the same instrument but with the AGC<sub>input</sub> cutoff moved to 110 dB SPL. In this case, the hearing instrument is not compressing the signals within the front end until they reach beyond 110 dB SPL.</p>
<fig id="fig6-1084713812471906" position="float">
<label>Figure 6.</label>
<caption>
<p>Input/output function with the level-shifting processing on and off for a 1 kHz sine signal</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig6.tif"/></fig>
<p>Even when the gain is increased by 4 dB in the hearing instrument, the effect is still clearly seen as shown in <xref ref-type="fig" rid="fig7-1084713812471906">Figure 7</xref>. To emphasize the functionality, an additional measurement with a 3 kHz sine signal was performed (<xref ref-type="fig" rid="fig8-1084713812471906">Figure 8</xref>).</p>
<fig id="fig7-1084713812471906" position="float">
<label>Figure 7.</label>
<caption>
<p>Input/output function with the level-shifting processing on and off for a 1 kHz sine signal—gain increased by 4 dB compared to <xref ref-type="fig" rid="fig6-1084713812471906">Figure 6</xref></p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig7.tif"/></fig>
<fig id="fig8-1084713812471906" position="float">
<label>Figure 8.</label>
<caption>
<p>Input/output function with the level-shifting processing on and off for a 3 kHz sine signal</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig8.tif"/></fig>
<p>The saturation knee point for the 3 kHz input is shifted toward lower input levels due to characteristics of the microphone resonances. Pure sine wave signals are not so common in music (except electronic music), so it is important to look at the effects that have been seen so far with recordings of music. In the following figures, we see recorded music displayed as waveforms with normalized amplitude on the <italic>y</italic>-axis and time on the <italic>x</italic>-axis. The black waveform is always the original signal while the gray represents the signal through the hearing instrument. In <xref ref-type="fig" rid="fig9-1084713812471906">Figures 9</xref> and <xref ref-type="fig" rid="fig10-1084713812471906">10</xref>, two gray .wav files for a 110 dB SPL peak input are shown that are recordings from a selection of music from the first movement (<italic>Vivace</italic>) of Beethoven’s Symphony No. 7.</p>
<fig id="fig9-1084713812471906" position="float">
<label>Figure 9.</label>
<caption>
<p>Recording with level-shifted processing; input level 110 dB SPL</p>
<p>Note: The black waveform is the original input file.</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig9.tif"/></fig>
<fig id="fig10-1084713812471906" position="float">
<label>Figure 10</label>
<caption>
<p>Recording with reference processing; input level 110 dB SPL</p>
<p>Note: The black waveform is the original input file.</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig10.tif"/></fig>
<p><xref ref-type="fig" rid="fig9-1084713812471906">Figures 9</xref> and <xref ref-type="fig" rid="fig10-1084713812471906">10</xref> clearly show the effect of the preserved dynamic range with the level-shifted processing in comparison with the reference signal where compression is applied to the signal at the input. This demonstrates that the natural dynamic characteristics will be converted into the digital domain with the level-shift. It is also of interest to see how the level-shifted processing affects smaller input levels. The following <xref ref-type="fig" rid="fig11-1084713812471906">Figures, 11</xref> and <xref ref-type="fig" rid="fig12-1084713812471906">12</xref> show the recordings with the same input signal but with a level of 90 dB SPL.</p>
<fig id="fig11-1084713812471906" position="float">
<label>Figure 11.</label>
<caption>
<p>Recording with level-shifted processing; input level 90 dB SPL</p>
<p>Note: The black waveform is the original input file.</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig11.tif"/></fig>
<fig id="fig12-1084713812471906" position="float">
<label>Figure 12.</label>
<caption>
<p>Recording with reference processing; input level 90 dB SPL</p>
<p>The black waveform is the original input file.</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig12.tif"/></fig>
<p>When the input is reduced, the effect heavily decreases and the reference processing can preserve the same dynamic behavior as the level-shifted processing. The effect has been shown so far by just one piece of orchestral music. To emphasize the effect, the following <xref ref-type="fig" rid="fig13-1084713812471906">Figures 13</xref> and <xref ref-type="fig" rid="fig14-1084713812471906">14</xref> show a recording with a 110 dB SPL peak input of a small brass ensemble playing a traditional American Jazz piece, <italic>St. James Infirmary</italic>. Again, the preservation of the dynamic range is clearly shown in <xref ref-type="fig" rid="fig13-1084713812471906">Figure 13</xref> compared to the reference processing in <xref ref-type="fig" rid="fig14-1084713812471906">Figure 14</xref>.</p>
<fig id="fig13-1084713812471906" position="float">
<label>Figure 13.</label>
<caption>
<p>Recording with level-shifted processing; input level 110 dB SPL</p>
<p>The black waveform is the original input file.</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig13.tif"/></fig>
<fig id="fig14-1084713812471906" position="float">
<label>Figure 14.</label>
<caption>
<p>Recording with reference processing; input level 110 dB SPL</p>
<p>The black waveform is the original input file.</p>
</caption>
<graphic xlink:href="10.1177_1084713812471906-fig14.tif"/></fig>
<p>These measurements were all made with recordings from CD sources (16-bit 44.1 kHz Stereophile and EMI) to ensure the reliability and repeatability of the measurements. It is possible, however, to predict that for live performances with a greater dynamic range the effects of the level-shift would be even greater.</p>
</sec>
</sec>
<sec id="section9-1084713812471906">
<title>Side Effects From the Level-shift</title>
<p>Are there any negative effects to the level-shift? When making this level-shift, there is one side effect that is generated. By attenuating the AGC<sub>input</sub>, all input levels are shifted and special care has to be taken into account for soft inputs. For hearing instrument users who have normal low-frequency hearing, the internal noise of the hearing instrument may be more audible in quiet environments than for a comparable program that is designed for speech without the level-shift. On the other hand, the level of the music (even <italic>pianissimo</italic>) is likely to be much more intense than the circuit noise, so any perceivable noise will probably be masked (M. Chasin, personal communication, October 19, 2012). To overcome this potential issue, in the level-shifted program, the threshold for the frequency-weighted expansion system was adjusted to compensate for this side effect. Expansion is the opposite of compression; more specifically, less gain is applied to soft sounds (<xref ref-type="bibr" rid="bibr67-1084713812471906">Venema, 2006</xref>). Expansion can reduce the internal noise within the hearing aid and additionally will also reduce low-level steady state environmental noise such as that produced by ventilation systems and so forth.</p>
</sec>
<sec id="section10-1084713812471906">
<title>Additional Considerations for Hearing Instrument Music Programs</title>
<p>It is possible to apply the input level-shift to different programs within a multimemory hearing instrument. The settings needed to make this change are, therefore, not global. So it is not necessary to have all end user settings with the level-shift engaged. The result is that a dedicated program can be used within the hearing instrument purely for music. In addition to the level-shift in the front end for higher input levels, is there anything else that can be done to make live music more enjoyable? With regard to a program for live music the following additional factors were considered: bandwidth and amplification, the use of automatic systems, and throughput delay.</p>
<sec id="section11-1084713812471906">
<title>Bandwidth and Amplification</title>
<p>It is well known that for normal hearing listeners a wide frequency response contributes to the perceived naturalness of music (<xref ref-type="bibr" rid="bibr47-1084713812471906">Moore &amp; Tan, 2003</xref>). Efforts were made to ensure that the frequency response of the hearing instruments using the level-shifts were as wide as possible—up to 10 kHz depending on the style and acoustic coupling method. It must be remembered, however, that hearing impaired listeners may not all prefer an extended high frequency response (<xref ref-type="bibr" rid="bibr24-1084713812471906">Franks, 1982</xref>; <xref ref-type="bibr" rid="bibr53-1084713812471906">Punch, 1978</xref>). This may be due to the individual’s hearing loss, where individuals with milder hearing losses prefer more high frequency bandwidth (<xref ref-type="bibr" rid="bibr55-1084713812471906">Ricketts et al., 2008</xref>). With regard to low-frequency amplification, <xref ref-type="bibr" rid="bibr24-1084713812471906">Franks (1982)</xref> concluded that hearing impaired listeners prefer an extended low-frequency response when listening to music. However, due to the use of open fittings, much of the low-frequency amplification of the hearing instrument is reduced while more of the natural low-frequency information passes naturally through the acoustic coupling to the ear. For a further discussion on hearing instrument bandwidth issues and music please see <xref ref-type="bibr" rid="bibr45-1084713812471906">Moore (2012)</xref>.</p>
<p>In addition to a wider bandwidth, the amount of compression prescribed by the fitting algorithm for the hearing instrument user was reduced in the music program with the level-shift applied. Using offset tables, a more linear response was provided by the fitting software. This is consistent with the studies that suggest different amplification strategies could be applied to music in contrast to speech (<xref ref-type="bibr" rid="bibr11-1084713812471906">Chasin &amp; Russo, 2004</xref>; <xref ref-type="bibr" rid="bibr18-1084713812471906">Davies-Venn, Souza, &amp; Fabry, 2007</xref>; <xref ref-type="bibr" rid="bibr65-1084713812471906">van Buuren, Festen, &amp; Houtgast, 1996</xref>, <xref ref-type="bibr" rid="bibr66-1084713812471906">1999</xref>). The clinician can of course apply the gain and adjust the compression parameters that are desirable for a particular hearing instrument user with the fitting software, so issues such as comfort or other specific requests can be easily accommodated.</p>
</sec>
<sec id="section12-1084713812471906">
<title>Automatic Features</title>
<p>When listening to music, it is important that all automatic features such as noise reduction and adaptive directionality are turned off. This is important to prevent these systems from interpreting the music as noise that may affect the sound quality (<xref ref-type="bibr" rid="bibr11-1084713812471906">Chasin &amp; Russo, 2004</xref>; <xref ref-type="bibr" rid="bibr57-1084713812471906">Russo, 2006</xref>). When sitting in a concert hall, it is often the case that the people in the seats around the listener make extraneous noise. Perhaps they are explaining what is happening on stage to their neighbor. Or, perhaps they are opening a sweet wrapper, which can be very disruptive, no matter how slowly they do it (<xref ref-type="bibr" rid="bibr39-1084713812471906">Kramer, 2000</xref>). Applause can also be very loud and disruptive while wearing hearing instruments in a concert. It is desirable therefore to select a fixed directional microphone setting, if needed, in a live music program, to place the focus on stage and not so much on the activities of the audience members around the listener.</p>
</sec>
<sec id="section13-1084713812471906">
<title>Throughput Delay</title>
<p>A number of studies have investigated the effect of throughput delay on sound quality. This delay refers to the sum of delays inherent in the signal path of the hearing instrument and typically falls below 10 ms (<xref ref-type="bibr" rid="bibr19-1084713812471906">Dillon, Keidser, O’Brien, &amp; Silberstein, 2003</xref>). Although studies testing delays in the range of 1 to &gt;10 ms in simulation have demonstrated negative effects on sound quality as judged by normal and impaired hearing listeners (<xref ref-type="bibr" rid="bibr60-1084713812471906">Stone &amp; Moore, 1999</xref>, <xref ref-type="bibr" rid="bibr61-1084713812471906">2002</xref>, <xref ref-type="bibr" rid="bibr62-1084713812471906">2003</xref>, <xref ref-type="bibr" rid="bibr63-1084713812471906">2005</xref>; <xref ref-type="bibr" rid="bibr64-1084713812471906">Stone, Moore, Meisenbacker, &amp; Derleth, 2008</xref>), these negative effects were not evident when testing in real hearing instruments worn by hearing impaired listeners (<xref ref-type="bibr" rid="bibr29-1084713812471906">Groth &amp; Sondergard, 2004</xref>). One study by <xref ref-type="bibr" rid="bibr69-1084713812471906">Zakis, Fulton, and Steele (2012)</xref> examined the effect of throughput delay on the sound quality of music in real hearing instruments. In this study, an attempt was made to create a worst case scenario by using open-canal hearing instruments with the gain set such that the likelihood of comb filtering was maximized. Comb filter effects were anticipated when the amplified signal and direct signal paths are combined in the ear canal of the listener. Twelve trained musicians listened to two selected music passages under three delay conditions (1.4, 2, and 3.4 ms) and a no-delay condition. Although differences in sound quality could be described by the musicians for each delay condition, and in some cases strong preferences were recorded for individuals, no significant difference was found between preferences assigned to each delay condition compared to the no-delay condition.</p>
</sec>
</sec>
<sec id="section14-1084713812471906">
<title>Experience With a Hearing Instrument Utilizing the Input Level-Shift</title>
<p>Dedicated programs for live music, which take account of the additional factors discussed above, are used in current hearing instruments. It is important to determine if subjective improvements can be found when the level-shift in the front end for higher input levels is implemented and used by individuals, who had reported previous poor experience with digital hearing instruments. <xref ref-type="bibr" rid="bibr31-1084713812471906">Hockley et al. (2010)</xref> conducted a study which looked at the ratings of sound quality attributes by 9 professional musicians (8 males and 1 female). Four of these musicians were woodwind players (clarinet, saxophone, and flute); 3 played jazz, while the other was a classical musician. Three of the musicians were classical violinists who also played the viola. The final two musicians were both rock (electric) guitarists. These individuals were all current users of analog K-AMP™ custom canal hearing instruments (<xref ref-type="bibr" rid="bibr36-1084713812471906">Killion, 1990</xref>, <xref ref-type="bibr" rid="bibr37-1084713812471906">1993</xref>). These individuals had not been able to wear digital hearing instruments due to their reports of unnatural sound quality, which ultimately disrupted the playing and enjoyment of music. The nine musicians were fitted with Micro BTE hearing instruments. Eight wore nonoccluding ear molds, while one used fully occluding earmolds.</p>
<p>The attribute scales used with the participants were based on the work of <xref ref-type="bibr" rid="bibr27-1084713812471906">Gabrielsson, Rosenberg, and Sjögren (1974)</xref>, <xref ref-type="bibr" rid="bibr28-1084713812471906">Gabrielsson and Sjögren (1979)</xref>, <xref ref-type="bibr" rid="bibr26-1084713812471906">Gabrielsson, Lindström, and Ove (1991)</xref>, and <xref ref-type="bibr" rid="bibr15-1084713812471906">Cox and Alexander (1983)</xref>. The scales consisted of qualitative descriptions of sound quality. Each participant gave a numerical rating toward the attribute that best suited what he or she experienced. Fullness is an example of an attribute that was used, where the perceptual dimension is from “full” to “thin.” Another example of an attribute that was measured is for naturalness, where the perceptual dimension is from “true to the source” to “artificial.” The participants were asked to compare, with the same hearing instruments, a program that applied the level-shift with a standard program that did not.</p>
<p>Overall, for the judgment of fullness, a program with the level-shift was judged to be significantly fuller than for the standard program without the level-shift. Overall fidelity for the level-shifted program was judged to be significantly better than for the standard program. There was no significant difference between the judgments of naturalness between the two programs due to a large variance in the response data; however, a trend was observed. In this small investigation it was concluded that the level-shift contributed to a better rating of sound quality for these musicians.</p>
</sec>
<sec id="section15-1084713812471906" sec-type="conclusions">
<title>Summary and Conclusions</title>
<p>Musicians and music enthusiasts have high expectations with regard to their hearing instrument performance for music. These expectations are rarely met. While continuing improvements in miniaturized transducers and bandwidth have helped, an opportunity exists to further improve performance for music by adapting the dynamic range of hearing instruments. This article described the implementation of a solution to accommodate the loud peaks of live music that would otherwise be compressed or even distorted before the A/D converter used in the 16-bit architecture applied in many hearing instruments today. The use of this level-shift preserves the dynamics of live music for musicians and music enthusiasts without affecting the battery life. As digital hearing instrument technology evolves toward 20-bit and even 24-bit architecture to accurately convey at least a 120 dB dynamic range, with less current consumption, then the use a level-shift will be obsolete. The use of a level-shift is the most practical solution for music for the hearing instrument architecture that is most commonly available today. The improvement was evident in the subjective assessment by a group of musicians who had previously rejected digital processing hearing instruments in favor of an analog instrument. As tested by <xref ref-type="bibr" rid="bibr31-1084713812471906">Hockley et al. (2010)</xref>, the judgments of sound quality revealed that when wearing digital hearing instruments, these musicians preferred a program with the level-shift engaged for live music.</p>
</sec>
</body>
<back>
<ack><p>The authors thank Stefan Marti, Simon Schüpbach, and Miquel Sans for their technical descriptions of the implementation and Christian Glück for programming the software for the LabVIEW tests. The authors also thank Jennifer Hockley, Barbara Simon, Christophe Lesimple, and an anonymous reviewer for comments on earlier versions of this article.</p></ack>
<fn-group>
<fn fn-type="other">
<label>Authors’ Note</label>
<p>The authors are paid employees of Bernafon AG, Berne, Switzerland.</p></fn>
<fn fn-type="conflict">
<label>Declaration of Conflicting Interests</label>
<p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></fn>
<fn fn-type="financial-disclosure">
<label>Funding</label>
<p>The authors received no financial support for the research, authorship, and/or publication of this article.</p></fn>
</fn-group>
<notes>
<fn-group>
<fn fn-type="other" id="fn1-1084713812471906">
<label>1.</label>
<p><xref ref-type="bibr" rid="bibr59-1084713812471906">Scollie et al. (2005)</xref> in their discussion of the DSL m[i/o] algorithm have proposed that these values should be changed to the following: Soft speech is 52 dB, Average speech is 60 dB, and Loud speech is 74 dB.</p></fn>
</fn-group>
</notes>
<ref-list>
<title>References</title>
<ref id="bibr1-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Agnew</surname><given-names>J.</given-names></name>
</person-group> (<year>2000</year>). <article-title>Digital hearing aid terminology made simple: A handy glossary</article-title>. <source>Hearing Journal</source>, <volume>53</volume>(<issue>3</issue>), <fpage>37</fpage>-<lpage>43</lpage>.</citation>
</ref>
<ref id="bibr2-1084713812471906">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Agnew</surname><given-names>J.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Amplifiers and circuit algorithms for contemporary hearing aids</article-title>. In <person-group person-group-type="editor">
<name><surname>Valente</surname><given-names>M.</given-names></name>
</person-group> (Ed.), <source>Hearing aids: Standards, options and limitations</source> (<edition>2nd ed.</edition>, pp. <fpage>101</fpage>-<lpage>142</lpage>), <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Thieme</publisher-name>.</citation>
</ref>
<ref id="bibr3-1084713812471906">
<citation citation-type="book"><collab>American National Standards Institute</collab>. (<year>1997</year>). ANSI S3.5-1997: <source>Methods for the calculation of the speech intelligibility index</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr4-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Behar</surname><given-names>A.</given-names></name>
<name><surname>Wong</surname><given-names>W.</given-names></name>
<name><surname>Kunov</surname><given-names>H.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Risk of hearing loss in orchestra musicians: Review of the literature</article-title>. <source>Medical Problems of Performing Artists</source>, <volume>21</volume>, <fpage>164</fpage>-<lpage>168</lpage>.</citation>
</ref>
<ref id="bibr5-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Byrne</surname><given-names>D.</given-names></name>
</person-group> (<year>1977</year>). <article-title>The speech spectrum: Some aspects of its significance for hearing aid selection and evaluation</article-title>. <source>British Journal of Audiology</source>, <volume>11</volume>, <fpage>40</fpage>-<lpage>46</lpage>.</citation>
</ref>
<ref id="bibr6-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Byrne</surname><given-names>D.</given-names></name>
<name><surname>Dillon</surname><given-names>H.</given-names></name>
<name><surname>Tran</surname><given-names>K.</given-names></name>
<name><surname>Arlinger</surname><given-names>S.</given-names></name>
<name><surname>Wilbraham</surname><given-names>K.</given-names></name>
<name><surname>Cox</surname><given-names>R.</given-names></name>
<name><surname>Ludvigsen</surname><given-names>C.</given-names></name>
</person-group> (<year>1994</year>). <article-title>An international comparison of long-term average speech spectra</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>96</volume>, <fpage>2108</fpage>-<lpage>2120</lpage>.</citation>
</ref>
<ref id="bibr7-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chasin</surname><given-names>M.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Music and hearing aids</article-title>. <source>Hearing Journal</source>, <volume>56</volume>(<issue>7</issue>), <fpage>36</fpage>-<lpage>41</lpage>.</citation>
</ref>
<ref id="bibr8-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chasin</surname><given-names>M.</given-names></name>
</person-group> (<year>2006a</year>). <article-title>Hearing aids for musicians</article-title>. <source>Hearing Review</source>, <volume>13</volume>(<issue>3</issue>), <fpage>11</fpage>-<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr9-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chasin</surname><given-names>M.</given-names></name>
</person-group> (<year>2006b</year>). <article-title>Can your hearing aid handle loud music? A quick test will tell you</article-title>. <source>Hearing Journal</source>, <volume>63</volume>(<issue>12</issue>), <fpage>22</fpage>-<lpage>24</lpage>.</citation>
</ref>
<ref id="bibr10-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chasin</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Six ways to improve listening to music through hearing aids</article-title>. <source>Hearing Journal</source>, <volume>63</volume>(<issue>9</issue>), <fpage>27</fpage>-<lpage>30</lpage>.</citation>
</ref>
<ref id="bibr11-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chasin</surname><given-names>M.</given-names></name>
<name><surname>Russo</surname><given-names>F. A.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Hearing aids and music</article-title>. <source>Trends in Amplification</source>, <volume>8</volume>(<issue>2</issue>), <fpage>35</fpage>-<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr12-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Chisolm</surname><given-names>T. H.</given-names></name>
<name><surname>Johnson</surname><given-names>C. E.</given-names></name>
<name><surname>Danhauer</surname><given-names>J. L.</given-names></name>
<name><surname>Portz</surname><given-names>L. J. P.</given-names></name>
<name><surname>Abrams</surname><given-names>H. B.</given-names></name>
<name><surname>Lesner</surname><given-names>S.</given-names></name>
<name><surname>Newman</surname><given-names>C. W.</given-names></name>
</person-group> (<year>2007</year>). <article-title>A systematic review of health-related quality of life and hearing aids: Final report of the American Academy of Audiology task force on the health-related quality of life benefits of amplification in adults</article-title>. <source>Journal of the American Academy of Audiology</source>, <volume>18</volume>, <fpage>151</fpage>-<lpage>183</lpage>.</citation>
</ref>
<ref id="bibr13-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Clark</surname><given-names>W. W.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Noise exposure from leisure activities: A review</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>90</volume>, <fpage>175</fpage>-<lpage>181</lpage>.</citation>
</ref>
<ref id="bibr14-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cornelisse</surname><given-names>L. E.</given-names></name>
<name><surname>Gagné</surname><given-names>J.-P.</given-names></name>
<name><surname>Seewald</surname><given-names>R. C.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Ear level recordings of the long-term average spectrum of speech</article-title>. <source>Ear and Hearing</source>, <volume>12</volume>(<issue>1</issue>), <fpage>47</fpage>-<lpage>54</lpage>.</citation>
</ref>
<ref id="bibr15-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Cox</surname><given-names>R. M.</given-names></name>
<name><surname>Alexander</surname><given-names>G. C.</given-names></name>
</person-group> (<year>1983</year>). <article-title>Acoustic versus electronic modifications of hearing aid low-frequency output</article-title>. <source>Ear and Hearing</source>, <volume>4</volume>, <fpage>190</fpage>-<lpage>196</lpage>.</citation>
</ref>
<ref id="bibr16-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Croghan</surname><given-names>N. B. H.</given-names></name>
<name><surname>Arehart</surname><given-names>K. H.</given-names></name>
<name><surname>Kates</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Quality and loudness judgements for music subjected to compression limiting</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>132</volume>, <fpage>1177</fpage>-<lpage>1188</lpage>.</citation>
</ref>
<ref id="bibr17-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Csermak</surname><given-names>B.</given-names></name>
<name><surname>Armstrong</surname><given-names>S.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Bits, bytes &amp; chips: Understanding digital hearing instruments</article-title>. <source>Hearing Review</source>, <volume>6</volume>(<issue>1</issue>), <fpage>8</fpage>-<lpage>12</lpage>.</citation>
</ref>
<ref id="bibr18-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Davies-Venn</surname><given-names>E.</given-names></name>
<name><surname>Souza</surname><given-names>P.</given-names></name>
<name><surname>Fabry</surname><given-names>D.</given-names></name>
</person-group> (<year>2007</year>). <article-title>Speech and music quality ratings for linear and nonlinear hearing aid circuitry</article-title>. <source>Journal of the American Academy of Audiology</source>, <volume>18</volume>, <fpage>688</fpage>-<lpage>699</lpage>.</citation>
</ref>
<ref id="bibr19-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dillon</surname><given-names>H.</given-names></name>
<name><surname>Keidser</surname><given-names>G.</given-names></name>
<name><surname>O’Brien</surname><given-names>A.</given-names></name>
<name><surname>Silberstein</surname><given-names>H.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Sound quality comparisons of advanced hearing aids</article-title>. <source>Hearing Journal</source>, <volume>56</volume>(<issue>4</issue>), <fpage>30</fpage>-<lpage>40</lpage>.</citation>
</ref>
<ref id="bibr20-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Dunn</surname><given-names>H. K.</given-names></name>
<name><surname>White</surname><given-names>S. D.</given-names></name>
</person-group> (<year>1940</year>). <article-title>Statistical measurements on conversational speech</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>11</volume>, <fpage>278</fpage>-<lpage>288</lpage>.</citation>
</ref>
<ref id="bibr21-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Edwards</surname><given-names>B.</given-names></name>
</person-group> (<year>2007</year>). <article-title>The future of hearing aid technology</article-title>. <source>Trends in Amplification</source>, <volume>11</volume>(<issue>1</issue>), <fpage>31</fpage>-<lpage>45</lpage>.</citation>
</ref>
<ref id="bibr22-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Fabiani</surname><given-names>M.</given-names></name>
<name><surname>Friberg</surname><given-names>A.</given-names></name>
</person-group> (<year>2011</year>). <article-title>Influence of pitch, loudness, and timbre on the perception of musical instruments</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>130</volume>, <fpage>EL193</fpage>-<lpage>EL199</lpage>.</citation>
</ref>
<ref id="bibr23-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Flugrath</surname><given-names>J. M.</given-names></name>
</person-group> (<year>1969</year>). <article-title>Modern-day rock-and-roll music and damage risk criteria</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>45</volume>, <fpage>704</fpage>-<lpage>711</lpage>.</citation>
</ref>
<ref id="bibr24-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Franks</surname><given-names>R. J.</given-names></name>
</person-group> (<year>1982</year>). <article-title>Judgements of hearing aid processed music</article-title>. <source>Ear and Hearing</source>, <volume>3</volume>(<issue>1</issue>), <fpage>18</fpage>-<lpage>23</lpage>.</citation>
</ref>
<ref id="bibr25-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>French</surname><given-names>N.</given-names></name>
<name><surname>Steinberg</surname><given-names>J.</given-names></name>
</person-group> (<year>1947</year>). <article-title>Factors governing the intelligibility of speech sounds</article-title>. <source>Journal of the Acoustical society of America</source>, <volume>19</volume>, <fpage>90</fpage>-<lpage>119</lpage>.</citation>
</ref>
<ref id="bibr26-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gabrielsson</surname><given-names>A.</given-names></name>
<name><surname>Lindström</surname><given-names>B.</given-names></name>
<name><surname>Ove</surname><given-names>T.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Loudspeaker frequency response and perceived sound quality</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>90</volume>, <fpage>707</fpage>-<lpage>719</lpage>.</citation>
</ref>
<ref id="bibr27-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gabrielsson</surname><given-names>A.</given-names></name>
<name><surname>Rosenberg</surname><given-names>U.</given-names></name>
<name><surname>Sjögren</surname><given-names>H.</given-names></name>
</person-group> (<year>1974</year>). <article-title>Judgements and dimension analyses of perceived sound quality of sound-reproducing systems</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>55</volume>, <fpage>854</fpage>-<lpage>861</lpage>.</citation>
</ref>
<ref id="bibr28-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gabrielsson</surname><given-names>A.</given-names></name>
<name><surname>Sjögren</surname><given-names>H.</given-names></name>
</person-group> (<year>1979</year>). <article-title>Perceived sound quality of hearing aids</article-title>. <source>Scandinavian Audiology</source>, <volume>8</volume>, <fpage>159</fpage>-<lpage>169</lpage>.</citation>
</ref>
<ref id="bibr29-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Groth</surname><given-names>J.</given-names></name>
<name><surname>Sondergaard</surname><given-names>M. B.</given-names></name>
</person-group> (<year>2004</year>). <article-title>Disturbance caused by varying propogation delay in non-occluding hearing aid fittings</article-title>. <source>International Journal of Audiology</source>, <volume>43</volume>, <fpage>594</fpage>-<lpage>599</lpage>.</citation>
</ref>
<ref id="bibr30-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hamacher</surname><given-names>V.</given-names></name>
<name><surname>Chalupper</surname><given-names>J.</given-names></name>
<name><surname>Eggers</surname><given-names>J.</given-names></name>
<name><surname>Fischer</surname><given-names>E.</given-names></name>
<name><surname>Kornagel</surname><given-names>U.</given-names></name>
<name><surname>Puder</surname><given-names>H.</given-names></name>
<name><surname>Rass</surname><given-names>U.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Signal processing in high-end hearing aids: State of the art, challenges, and future trends</article-title>. <source>Journal on Applied Signal Processing</source>, <volume>18</volume>, <fpage>2915</fpage>-<lpage>2929</lpage>.</citation>
</ref>
<ref id="bibr31-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hockley</surname><given-names>N. S.</given-names></name>
<name><surname>Bahlmann</surname><given-names>F.</given-names></name>
<name><surname>Chasin</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Programming hearing instruments to make live music more enjoyable</article-title>. <source>Hearing Journal</source>, <volume>63</volume>(<issue>9</issue>), <fpage>30</fpage>-<lpage>38</lpage>.</citation>
</ref>
<ref id="bibr32-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hunter</surname><given-names>L. L.</given-names></name>
<name><surname>Ries</surname><given-names>D. T.</given-names></name>
<name><surname>Schlauch</surname><given-names>R. S.</given-names></name>
<name><surname>Levine</surname><given-names>S. C.</given-names></name>
<name><surname>Ward</surname><given-names>W. D.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Safety and clinical performance of acoustic reflex tests</article-title>. <source>Ear and Hearing</source>, <volume>20</volume>, <fpage>506</fpage>-<lpage>514</lpage>.</citation>
</ref>
<ref id="bibr33-1084713812471906">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Kates</surname><given-names>J. M.</given-names></name>
</person-group> (<year>2008</year>). <source>Digital hearing aids</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Plural</publisher-name>.</citation>
</ref>
<ref id="bibr34-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Keidser</surname><given-names>G.</given-names></name>
<name><surname>Dillon</surname><given-names>H.</given-names></name>
<name><surname>Flax</surname><given-names>M.</given-names></name>
<name><surname>Ching</surname><given-names>T.</given-names></name>
<name><surname>Brewer</surname><given-names>S.</given-names></name>
</person-group> (<year>2011</year>). <article-title>The NAL-NL2 prescription procedure</article-title>. <source>Audiology Research</source>, <volume>1</volume>, <fpage>e24</fpage>.</citation>
</ref>
<ref id="bibr35-1084713812471906">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Killion</surname><given-names>M. C.</given-names></name>
</person-group> (<year>1988</year>). <article-title>Technological report: An “acoustically invisible” hearing aid</article-title>. <source>Hearing Instruments</source>, <volume>39</volume>(<issue>10</issue>). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.etymotic.com">www.etymotic.com</ext-link></citation>
</ref>
<ref id="bibr36-1084713812471906">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Killion</surname><given-names>M. C.</given-names></name>
</person-group> (<year>1990</year>). <article-title>A high fidelity hearing aid</article-title>. <source>Hearing Instruments</source>, <volume>41</volume>(<issue>8</issue>). Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.etymotic.com">www.etymotic.com</ext-link></citation>
</ref>
<ref id="bibr37-1084713812471906">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Killion</surname><given-names>M. C.</given-names></name>
</person-group> (<year>1993</year>). <article-title>The K-AMP hearing aid: An attempt to present high fidelity for the hearing impaired</article-title>. In <person-group person-group-type="editor">
<name><surname>Beilin</surname><given-names>J.</given-names></name>
<name><surname>Jensen</surname><given-names>G. R.</given-names></name>
</person-group> (Eds.), <conf-name>Recent developments in hearing instrument technology: 15th Danavox Symposium</conf-name> (pp. <fpage>167</fpage>-<lpage>229</lpage>). <conf-loc>Copenhagen, Denmark: Stougaard Jensen</conf-loc>.</citation>
</ref>
<ref id="bibr38-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Killion</surname><given-names>M. C.</given-names></name>
</person-group> (<year>2009</year>). <article-title>What special hearing aid properties do performing musicians require?</article-title> <source>Hearing Review</source>, <volume>16</volume>(<issue>2</issue>), <fpage>20</fpage>-<lpage>31</lpage>.</citation>
</ref>
<ref id="bibr39-1084713812471906">
<citation citation-type="confproc">
<person-group person-group-type="author">
<name><surname>Kramer</surname><given-names>E. M.</given-names></name>
</person-group> (<year>2000</year>, <month>June</month> <day>2</day>). <source>On the noise from a crumpled candy wrapper</source>. <conf-name>Popular version of paper 4pPa2 presented at the Acoustical Society of America 139th Meeting</conf-name>, <conf-loc>Atlanta, GA</conf-loc>.</citation>
</ref>
<ref id="bibr40-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ladefoged</surname><given-names>P.</given-names></name>
<name><surname>McKinney</surname><given-names>N. P.</given-names></name>
</person-group> (<year>1963</year>). <article-title>Loudness, sound pressure and subglottal pressure in speech</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>35</volume>, <fpage>454</fpage>-<lpage>460</lpage>.</citation>
</ref>
<ref id="bibr41-1084713812471906">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Levitin</surname><given-names>D. J.</given-names></name>
</person-group> (<year>2006</year>). <source>This is your brain on music: The science of a human obsession</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Dutton/Penguin</publisher-name>.</citation>
</ref>
<ref id="bibr42-1084713812471906">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lyons</surname><given-names>R. G.</given-names></name>
</person-group> (<year>2004</year>). <source>Understanding digital signal processing</source> (<edition>2nd ed.</edition>). <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>.</citation>
</ref>
<ref id="bibr43-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>MacDonald</surname><given-names>E. N.</given-names></name>
<name><surname>Behar</surname><given-names>A.</given-names></name>
<name><surname>Wong</surname><given-names>W.</given-names></name>
<name><surname>Kunov</surname><given-names>H.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Noise exposure of opera musicians</article-title>. <source>Canadian Acoustics</source>, <volume>36</volume>(<issue>4</issue>), <fpage>11</fpage>-<lpage>16</lpage>.</citation>
</ref>
<ref id="bibr44-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Menon</surname><given-names>V.</given-names></name>
<name><surname>Levitin</surname><given-names>D. J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The rewards of music listening: Response and physiological connectivity of the mesolimbic system</article-title>. <source>NeuroImage</source>, <volume>28</volume>, <fpage>175</fpage>-<lpage>184</lpage>.</citation>
</ref>
<ref id="bibr45-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Effects of bandwidth, compression speed, and gain at high frequencies on preferences for amplified music</article-title>. <source>Trends in Amplification</source>, <volume>16</volume>, <fpage>159</fpage>-<lpage>172</lpage>.</citation>
</ref>
<ref id="bibr46-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
<name><surname>Glasberg</surname><given-names>B. R.</given-names></name>
<name><surname>Stone</surname><given-names>M. A.</given-names></name>
</person-group> (<year>2010</year>). <article-title>Development of a new method for deriving initial fittings for hearing aids with multi-channel compression: CAMEQ2-HF</article-title>. <source>International Journal of Audiology</source>, <volume>49</volume>, <fpage>216</fpage>-<lpage>227</lpage>.</citation>
</ref>
<ref id="bibr47-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
<name><surname>Tan</surname><given-names>C.-T.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Perceived naturalness of spectrally distorted speech and music</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>114</volume>, <fpage>408</fpage>-<lpage>418</lpage>.</citation>
</ref>
<ref id="bibr48-1084713812471906">
<citation citation-type="book"><collab>National Council on the Aging</collab>. (<year>1999</year>). <source>The consequences of untreated hearing loss in older persons</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>Author</publisher-name>.</citation>
</ref>
<ref id="bibr49-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Olsen</surname><given-names>W. A.</given-names></name>
</person-group> (<year>1998</year>). <article-title>Average speech levels and spectra in various speaking/listening conditions: A summary of the Pearson, Bennett, and Fidell (1977) report</article-title>. <source>American Journal of Audiology</source>, <volume>7</volume>, <fpage>1</fpage>-<lpage>5</lpage>.</citation>
</ref>
<ref id="bibr50-1084713812471906">
<citation citation-type="web">
<person-group person-group-type="author">
<name><surname>Pawlaczyk-Luszynska</surname><given-names>M.</given-names></name>
<name><surname>Dudarewicz</surname><given-names>A.</given-names></name>
<name><surname>Zamoijska</surname><given-names>M.</given-names></name>
<name><surname>Sliwinska-Kowalska</surname><given-names>M.</given-names></name>
</person-group> (<year>2010</year>, <month>June</month>). <source>Evaluation of sound exposure and risk of hearing impairment in orchestral musicians</source>. <conf-name>Paper presented at the 15th International Conference on Noise Control</conf-name>, <conf-loc>Ksiaz-Wroclaw, Poland</conf-loc>. Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.earcom.pl">www.earcom.pl</ext-link></citation>
</ref>
<ref id="bibr51-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Phillips</surname><given-names>S. L.</given-names></name>
<name><surname>Mace</surname><given-names>S.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Sound level measurements in music practice rooms</article-title>. <source>Music Performance Research</source>, <volume>2</volume>, <fpage>36</fpage>-<lpage>47</lpage>.</citation>
</ref>
<ref id="bibr52-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Poissant</surname><given-names>S. F.</given-names></name>
<name><surname>Freyman</surname><given-names>R. L.</given-names></name>
<name><surname>MacDonald</surname><given-names>A. J.</given-names></name>
<name><surname>Nunes</surname><given-names>H. A.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Characteristics of noise exposure during solitary trumpet playing: Immediate impact on distortion-product otoacoustic emissions and long-term implications for hearing</article-title>. <source>Ear and Hearing</source>, <volume>33</volume>, <fpage>543</fpage>-<lpage>553</lpage>.</citation>
</ref>
<ref id="bibr53-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Punch</surname><given-names>J. L.</given-names></name>
</person-group> (<year>1978</year>). <article-title>Quality judgements of hearing aid-processed speech and music by normal and otopathologic listeners</article-title>. <source>Journal of the American Auditory Society</source>, <volume>3</volume>, <fpage>179</fpage>-<lpage>188</lpage>.</citation>
</ref>
<ref id="bibr54-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Revit</surname><given-names>L. J.</given-names></name>
</person-group> (<year>2009</year>). <article-title>What’s so special about music?</article-title> <source>Hearing Review</source>, <volume>16</volume>(<issue>2</issue>), <fpage>12</fpage>-<lpage>19</lpage>.</citation>
</ref>
<ref id="bibr55-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ricketts</surname><given-names>T. A.</given-names></name>
<name><surname>Dittberner</surname><given-names>A. B.</given-names></name>
<name><surname>Johnson</surname><given-names>E. E.</given-names></name>
</person-group> (<year>2008</year>). <article-title>High-frequency amplification and sound quality in listeners with normal through moderate hearing loss</article-title>. <source>Journal of Speech, Language and Hearing Research</source>, <volume>51</volume>, <fpage>160</fpage>-<lpage>172</lpage>.</citation>
</ref>
<ref id="bibr56-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Royster</surname><given-names>J. D.</given-names></name>
<name><surname>Royster</surname><given-names>L. H.</given-names></name>
<name><surname>Killion</surname><given-names>M. C.</given-names></name>
</person-group> (<year>1991</year>). <article-title>Sound exposures and hearing thresholds of symphony orchestra musicians</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>89</volume>, <fpage>2793</fpage>-<lpage>2803</lpage>.</citation>
</ref>
<ref id="bibr57-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Russo</surname><given-names>F. A.</given-names></name>
</person-group> (<year>2006</year>). <article-title>Perceptual considerations in designing and fitting hearing aids for music</article-title>. <source>Hearing Review</source>, <volume>13</volume>(<issue>3</issue>), <fpage>74</fpage>-<lpage>78</lpage>.</citation>
</ref>
<ref id="bibr58-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Ryan</surname><given-names>J.</given-names></name>
<name><surname>Tewari</surname><given-names>S. A.</given-names></name>
</person-group> (<year>2009</year>). <article-title>A digital signal processor for musicians and audiophiles</article-title>. <source>Hearing Review</source>, <volume>16</volume>(<issue>2</issue>), <fpage>38</fpage>-<lpage>41</lpage>.</citation>
</ref>
<ref id="bibr59-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Scollie</surname><given-names>S.</given-names></name>
<name><surname>Seewald</surname><given-names>R.</given-names></name>
<name><surname>Cornelisse</surname><given-names>L.</given-names></name>
<name><surname>Moodie</surname><given-names>S.</given-names></name>
<name><surname>Bagatto</surname><given-names>M.</given-names></name>
<name><surname>Launagaray</surname><given-names>D.</given-names></name>
<name><surname>Pumford</surname><given-names>M.</given-names></name>
</person-group> (<year>2005</year>). <article-title>The desired sensation level multistage input/output algorithm</article-title>. <source>Trends in Amplification</source>, <volume>9</volume>, <fpage>159</fpage>-<lpage>197</lpage>.</citation>
</ref>
<ref id="bibr60-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>M. A.</given-names></name>
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Tolerable hearing aid delays: I. Estimation of limits imposed by the auditory pathway alone using simulated hearing losses</article-title>. <source>Ear and Hearing</source>, <volume>20</volume>, <fpage>182</fpage>-<lpage>192</lpage>.</citation>
</ref>
<ref id="bibr61-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>M. A.</given-names></name>
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
</person-group> (<year>2002</year>). <article-title>Tolerable hearing aid delays: II. Estimation of limits imposed during speech production</article-title>. <source>Ear and Hearing</source>, <volume>23</volume>, <fpage>325</fpage>-<lpage>338</lpage>.</citation>
</ref>
<ref id="bibr62-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>M. A.</given-names></name>
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
</person-group> (<year>2003</year>). <article-title>Tolerable hearing aid delays: III. Effects on speech production and perception of across-frequency variation in delay</article-title>. <source>Ear and Hearing</source>, <volume>24</volume>, <fpage>175</fpage>-<lpage>183</lpage>.</citation>
</ref>
<ref id="bibr63-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>M. A.</given-names></name>
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Tolerable hearing aid delays: IV. Effects on subjective disturbance during speech production by hearing-impaired subjects</article-title>. <source>Ear and Hearing</source>, <volume>26</volume>, <fpage>225</fpage>-<lpage>235</lpage>.</citation>
</ref>
<ref id="bibr64-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Stone</surname><given-names>M. A.</given-names></name>
<name><surname>Moore</surname><given-names>B. C. J.</given-names></name>
<name><surname>Meisenbacker</surname><given-names>K.</given-names></name>
<name><surname>Derleth</surname><given-names>R. P.</given-names></name>
</person-group> (<year>2008</year>). <article-title>Tolerable hearing aid delays: V. Estimation of limits for open canal fittings</article-title>. <source>Ear and Hearing</source>, <volume>29</volume>, <fpage>601</fpage>-<lpage>617</lpage>.</citation>
</ref>
<ref id="bibr65-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van Buuren</surname><given-names>R. A.</given-names></name>
<name><surname>Festen</surname><given-names>J. M.</given-names></name>
<name><surname>Houtgast</surname><given-names>T.</given-names></name>
</person-group> (<year>1996</year>). <article-title>Peaks in the frequency response of hearing aids: Evaluation of the effects on speech intelligibility and sound quality</article-title>. <source>Journal of Speech and Hearing Research</source>, <volume>39</volume>, <fpage>239</fpage>-<lpage>250</lpage>.</citation>
</ref>
<ref id="bibr66-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>van Buuren</surname><given-names>R. A.</given-names></name>
<name><surname>Festen</surname><given-names>J. M.</given-names></name>
<name><surname>Houtgast</surname><given-names>T.</given-names></name>
</person-group> (<year>1999</year>). <article-title>Compression and expansion of the temporal envelope: Evaluation of speech intelligibility and sound quality</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>105</volume>, <fpage>2903</fpage>-<lpage>2913</lpage>.</citation>
</ref>
<ref id="bibr67-1084713812471906">
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Venema</surname><given-names>T. H.</given-names></name>
</person-group> (<year>2006</year>). <source>Compression for clinicians</source> (<edition>2nd ed.</edition>). <publisher-loc>Clifton Park, NY</publisher-loc>: <publisher-name>Delmar Cengage Learning</publisher-name>.</citation>
</ref>
<ref id="bibr68-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zakis</surname><given-names>J. A.</given-names></name>
<name><surname>Fulton</surname><given-names>B.</given-names></name>
</person-group> (<year>2009</year>). <article-title>How can digital signal processing help musicians?</article-title> <source>Hearing Review</source>, <volume>16</volume>(<issue>5</issue>),<fpage>44</fpage>-<lpage>48</lpage>.</citation>
</ref>
<ref id="bibr69-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zakis</surname><given-names>J. A.</given-names></name>
<name><surname>Fulton</surname><given-names>B.</given-names></name>
<name><surname>Steele</surname><given-names>B.</given-names></name>
</person-group> (<year>2012</year>). <article-title>Preferred delay and phase-frequency response of open-canal hearing aids with music at low insertion gain</article-title>. <source>International Journal of Audiology</source>, <volume>51</volume>, <fpage>906</fpage>-<lpage>913</lpage>.</citation>
</ref>
<ref id="bibr70-1084713812471906">
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Zatorre</surname><given-names>R.</given-names></name>
</person-group> (<year>2005</year>). <article-title>Music, the food of neuroscience?</article-title> <source>Nature</source>, <volume>434</volume>, <fpage>312</fpage>-<lpage>315</lpage>.</citation>
</ref>
</ref-list>
</back>
</article>