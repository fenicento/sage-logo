<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">PIE</journal-id>
<journal-id journal-id-type="hwp">sppie</journal-id>
<journal-title>Proceedings of the Institution of Mechanical Engineers, Part E: Journal of Process Mechanical Engineering</journal-title>
<issn pub-type="ppub">0954-4089</issn>
<issn pub-type="epub">2041-3009</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage UK: London, England</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0954408912459161</article-id>
<article-id pub-id-type="publisher-id">10.1177_0954408912459161</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A novel fault analysis and diagnosis method based on combining computational intelligence methods</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Deng</surname><given-names>Wu</given-names></name>
<xref ref-type="aff" rid="aff1-0954408912459161">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Yang</surname><given-names>Xinhua</given-names></name>
<xref ref-type="aff" rid="aff2-0954408912459161">2</xref>
<xref ref-type="corresp" rid="corresp1-0954408912459161"/>
</contrib>
<contrib contrib-type="author">
<name><surname>Liu</surname><given-names>Jingjing</given-names></name>
<xref ref-type="aff" rid="aff1-0954408912459161">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Zhao</surname><given-names>Huimin</given-names></name>
<xref ref-type="aff" rid="aff1-0954408912459161">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Li</surname><given-names>Zhengguang</given-names></name>
<xref ref-type="aff" rid="aff1-0954408912459161">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Yan</surname><given-names>Xiaolin</given-names></name>
<xref ref-type="aff" rid="aff2-0954408912459161">2</xref>
</contrib>
</contrib-group>
<aff id="aff1-0954408912459161"><label>1</label>Software Institute, Dalian Jiaotong University, Dalian, P.R. China</aff>
<aff id="aff2-0954408912459161"><label>2</label>School of Materials Science and Engineering, Dalian Jiaotong University, Dalian, P.R. China</aff>
<author-notes>
<corresp id="corresp1-0954408912459161">Xinhua Yang, School of Materials Science and Engineering, Dalian Jiaotong University, Dalian 116028, P.R. China. Email: <email>dw7689@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>8</month>
<year>2013</year>
</pub-date>
<volume>227</volume>
<issue>3</issue>
<fpage>198</fpage>
<lpage>210</lpage>
<history>
<date date-type="received"><day>1</day><month>5</month><year>2012</year></date>
<date date-type="accepted"><day>2</day><month>8</month><year>2012</year></date>
</history>
<permissions>
<copyright-statement>© IMechE 2012 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav</copyright-statement>
<copyright-year>2012</copyright-year>
<copyright-holder content-type="society">Institution of Mechanical Engineers</copyright-holder>
</permissions>
<abstract>
<p>In order to improve the correctness and efficiency of fault diagnosis, a novel hybrid intelligence method based on integrating rough set, genetic algorithms, and radial basic function neural network (RGRN) was proposed for motor fault diagnosis in the complicated CNC system in this article. In the proposed RGRN method, combination and condition supplement algorithm was used to deal with the incomplete fault data and the original data were discretized using genetic algorithms to construct a decision table. Rough set theory as a new mathematical tool was used to eliminate the redundant and irrelevant attributes in order to obtain the minimum rule set for reducing the number of input nodes of the radial basic function neural network. Genetic algorithms were directly used to optimize the structure and weights of radial basic function neural network to establish an optimized radial basic function neural network (GRN) model; then, the minimum rule set was inputted into the GRN model in order to obtain the optimized RGRN model. Finally, the completed fault symptom information was inputted into the RGRN model to obtain the fault diagnosis results. The robustness of the RGRN method was tested. Simulating experiments on motor fault diagnosis in the complicated CNC system show the RGRN method not only improves the global optimization performance and quickens the convergence speed, but also obtains the robust solution with a better quality.</p>
</abstract>
<kwd-group>
<kwd>Computational intelligence</kwd>
<kwd>hybrid intelligence method</kwd>
<kwd>fault analysis and diagnosis</kwd>
<kwd>completeness</kwd>
<kwd>complicated CNC system</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="sec1-0954408912459161" sec-type="intro"><title>Introduction</title>
<p>Faults as critical conditions or abnormal situations in industry are a range of abnormal operating states that are beyond a normal state, but fall short of automated shutdowns, such as those that take place during an emergency. Typically, these conditions are the consequences of combinations of events that unexpectedly occur at the same time. Faults are also understood as any kind of fault in the actual dynamic running system. Such faults could result from process variables, process components, or even basic control systems. If the system behavior is regarded as malfunctioning, then the appropriate fault diagnosis (FD)<sup><xref ref-type="bibr" rid="bibr1-0954408912459161">1</xref></sup> mechanism can be used to detect the faulty activity. Consequently, the developing reliable methods for fault detection and isolation have become an important research field in control engineering. So, FD plays an important role in the operation and maintenance of the actual dynamic running system, which can not only reduce or eliminate the accident, but also bring the applied potential and reduce expenditure. Besides the accuracy, the speed of the FD is a very important factor. Therefore, an accurate and fast FD method is an essential issue.</p>
<p>The FD method began in the early 1970s and has been receiving more and more attention in the past two decades. The increasing interests are applied for two major applications: academic research and industrial application due to safety-related matters.<sup><xref ref-type="bibr" rid="bibr2-0954408912459161">2</xref></sup> Fault detection and diagnosis are of great significance in processing systems. Early fault detection helps to avoid incidents, process upsets, product deterioration, performance degradation, major damage to the system itself, and damage to human health or even loss of lives. FD can be performed by employing different approaches.</p>
<p>Computer technology, with its rapid development, has eased the effort of data acquisition from industrial applications (e.g. traffic, power systems, manufacturing industries, civil and building engineering, etc.). The sample data, which are collected from industrial running systems, often include a lot of important information. The sample data also include various kinds of uncertain attributes by the system parameters, system structure, and in the environment in which the system operates.<sup><xref ref-type="bibr" rid="bibr3-0954408912459161">3</xref>,<xref ref-type="bibr" rid="bibr4-0954408912459161">4</xref></sup> Therefore, one of the main challenges is how to effectively analyze the sample data and extract useful information from the sample data so that informed decisions can be formed.</p>
<p>Classification is one of the main approaches to obtain useful information from sample data, which can provide solutions to the problems in hand. Artificial intelligence is a popular intelligent method for data classification. Computational intelligence consists of neural network (NN), fuzzy logic, rough set theory (RST), swarm computing, etc. It is a novel technology to bring intelligence into the computation. Compared with the traditional artificial intelligence, one significant characteristic of computational intelligence is that precise models need not be established when it deals with imprecise, uncertain, and incomplete information. Therefore, it is especially useful for solving valid and formalized model problems. It is also effective to deal with the combinational problem in complicated running systems. NN and genetic algorithms (GAs) can simulate human activities. These algorithms are very practical and useful to solve real-world problems where deterministic solutions are hard to obtain.</p>
<p>In many situations, researchers try combining different computational intelligence methods in order to create some powerful tools. We take the full advantages of RST, GAs, and radial basis function neural network (RBFNN). RST can reduce knowledge and simplify knowledge expression space dimension. GAs have the characteristics of distributed computing and the positive feedback mechanism. RBFNN has non-linear, self-adaptive, and self-organization properties. A novel hybrid intelligent algorithm based on combining RST, GAs, and RBFNN (shortly RGRN) is proposed in this article. In the proposed hybrid intelligence algorithm, GAs are used to optimize the structure and parameters of RBFNN to construct the optimized GRN network model. Rough set is used to reduce and simplify the input dimension. The RGRN model is used to carry out the FD in a complicated computer numerical control (CNC) system.</p>
<p>The rest of this article is organized as follows. The following section describes the incomplete complicated system. Then, the concepts of computational intelligence, including RST, GAs, and RBFNN are briefly reviewed. The next section introduces how to combine RBFNN and GAs. ‘Hybrid intelligence FD method in a complicated CNC system’ presents a new method named RGRN algorithm. The detailed implementation steps of RGRN method for vibration FD in the complicated CNC system are illustrated. ‘Experiment simulation’ tests and validates the correctness of the proposed RGRN method for vibration FD in the complicated CNC system. Finally, the conclusions are discussed.</p>
</sec>
<sec id="sec2-0954408912459161"><title>Incomplete information system</title>
<p>Information system is composed of computer hardware, network and communication equipment, computer software, information resource, information users, and regulations in order to process information flow of man–machine system. According to the data in this system, information system is divided into incomplete information system and complete information system. If a missing data or null value exists in the information system, it is called an incomplete information system. Incompleteness is a very important feature to make a mistake in current complicated CNC system. So, intelligent FD is a significant method to solve FD in the current complicated CNC system. However, in the accrual FD as a result of the complicatedity of the system, there are serious incomplete fault symptoms, such as null value, missing value, unknown value, uncertain values, sparse data, etc.</p>
<sec id="sec3-0954408912459161"><title>Incomplete information system</title>
<p>Let an information system be a four tuple <italic>S</italic> = {<italic>U</italic>, <italic>A</italic>, <italic>V</italic>, <italic>F</italic>}, where <italic>U</italic> is a non-empty finite set of objects, called the universe, <italic>A = C ∪ D</italic> a non-empty finite set of attributes, <italic>C</italic> a set of condition attributes and <italic>D</italic> a set of decision attributes, <italic>C </italic><inline-formula id="ilm1-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math1-0954408912459161"><mml:mrow><mml:mo>∩</mml:mo></mml:mrow></mml:math></inline-formula><italic> D</italic> = φ. Each attribute <italic>a </italic><inline-formula id="ilm2-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math2-0954408912459161"><mml:mrow><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula> <italic>A</italic> is associated with a set <italic>V<sub>a</sub></italic> of its value, which designates each object <italic>x</italic> attribute value in <italic>U</italic>, called the domain of <italic>a</italic>. If there exists at least <italic>a </italic>∈ <italic>A</italic>, <italic>V<sub>a</sub></italic> includes a null value (or missing value, or unknown value, or uncertain value) (using * expression) and *<inline-formula id="ilm3-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math3-0954408912459161"><mml:mrow><mml:mo>∉</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Then, the system is an incomplete FD system.<sup><xref ref-type="bibr" rid="bibr5-0954408912459161">5</xref>,<xref ref-type="bibr" rid="bibr6-0954408912459161">6</xref></sup></p>
<p>In the incomplete FD system, if the null value (or missing value, or unknown value, or uncertain value) appears in the value domain of symptom attributes, these values will be processed. So, the null value (or missing value, or unknown value, or uncertain value) is existent in the incomplete FD system; it is only a temporary vacancy because of some irresistible subjectivity and objectivity. We think that null value (or missing value, or unknown value, or uncertain value) definitely belongs to the idiographic attribute value in the incomplete FD system.</p>
</sec>
<sec id="sec4-0954408912459161"><title>The characteristics and completion processing method of incomplete information system</title>
<p>All kinds of FDs in a complicated system are varied and have some commonness in essence. So, several basic characteristics are gained by analyzing and summarizing faults in a complicated system: (1) fault complicatedity, (2) fault hierarchy; (3) fault relativity; (4) fault delay; (5) fault uncertainty; and (6) fault regularity.</p>
<p>For FD in the complicated system, the existing shortcomings of null value (or missing value, or unknown value, or uncertain value) are: (1) lose useful information; (2) increase the uncertainty of the system; and (3) cause unreliable output.</p>
<p>In order to improve the correctness and efficiency of FD, there is a need to process the incomplete information. At present, the common completeness process method includes: (1) change incomplete information into the possible complete information; (2) delete the unknown value; and (3) replace the unknown value with the most possible value or the predicted value.</p>
<p>These completeness process methods will transform incomplete information into a complete one. Nevertheless, the dominating research method for the incompleteness information process is to take the reasonable supplement of the missing data. The main complement algorithms are: (1) supplement algorithm of average value; (2) supplement algorithm of conditional average; and (3) supplement algorithm of the combined condition.</p>
<p>In this article, the supplement algorithm of the combined condition was used to make the reasonable supplement for missing data. This method selects all attribute values of the identical decision case to test in the decision table. Also, the best result is selected from the final reduction results as a supplemental result.</p>
</sec>
</sec>
<sec id="sec5-0954408912459161"><title>Computational intelligence</title>
<p>Computational intelligence<sup><xref ref-type="bibr" rid="bibr7-0954408912459161">7</xref></sup> is a new category of algorithms, including evolutionary computing, fuzzy computing, rough set, artificial neural network (ANN) and granular computing, swarm computing, etc. The wide applications of these intelligence algorithms have proven that they are very useful in practice for solving actual problems, especially for those problems of obtaining hard deterministic solutions. In many situations, researchers attempt to combine various computational intelligence methods in order to create more powerful methods for solving the actual complex problems.</p>
<sec id="sec6-0954408912459161"><title>Rough set theory</title>
<p>RST<sup><xref ref-type="bibr" rid="bibr8-0954408912459161">8</xref></sup> is a new mathematical approach that can be employed to handle imprecision, incompletion, vagueness, and uncertainty. It has been applied in knowledge discovery, decision analysis, pattern recognition, data mining, machine learning, process control, and other artificial intelligence areas for decades. RST can discover the implicit knowledge and find out the potentially useful rule by analyzing and dealing with all kinds of imprecise, incomplete, and inconsistent information. Rough set is a vague concept approximation by the precise concepts of the lower and upper approximations. Lower approximation is a description of the domain objects which are known with certainty to belong to the subset of interest, whereas upper approximation is a description of the objects which possibly belong to the subset. Relative to a given set of attributes, a set is rough if its lower and upper approximations are not equal.</p>
<p>Let <italic>I</italic>  =  (<italic>U</italic>, <italic>A</italic>) be an information system, where <italic>U</italic> is the universe, a non-empty finite set of objects and <italic>A</italic> a non-empty finite set of attributes such that <italic>a</italic>: <inline-formula id="ilm4-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math4-0954408912459161"><mml:mrow><mml:mi>U</mml:mi><mml:mo>→</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For any <italic>P </italic><inline-formula id="ilm5-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math5-0954408912459161"><mml:mrow><mml:mo>⊆</mml:mo></mml:mrow></mml:math></inline-formula> <italic>A</italic>, there is an associated equivalence relation <inline-formula id="ilm6-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math6-0954408912459161"><mml:mrow><mml:mi>IND</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The definition of <inline-formula id="ilm7-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math7-0954408912459161"><mml:mrow><mml:mi>IND</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is listed as follows.<sup><xref ref-type="bibr" rid="bibr9-0954408912459161">9</xref></sup>
<disp-formula id="disp-formula1-0954408912459161"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math1-0954408912459161"><mml:mrow><mml:mi>IND</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>×</mml:mo><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mo>∀</mml:mo><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula1-0954408912459161" xlink:href="10.1177_0954408912459161-eq1.tif"/></disp-formula>
</p>
<p>If (<italic>x</italic>, <italic>y</italic>) <inline-formula id="ilm8-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math8-0954408912459161"><mml:mrow><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula> <inline-formula id="ilm9-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math9-0954408912459161"><mml:mrow><mml:mi>IND</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, then <italic>x</italic> and <italic>y</italic> are indiscernible by attributes from <italic>P</italic>. The partition of <italic>U</italic>, generated by <italic>IND</italic>(<italic>P</italic>) is denoted as <italic>U</italic>/<italic>P</italic>. The equivalence classes of the <italic>P</italic>-indiscernibility relation are denoted as <inline-formula id="ilm10-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math10-0954408912459161"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The indiscernibility relation is the mathematical basis of RST. The <italic>U</italic>/<italic>P</italic> can be calculated as follows
<disp-formula id="disp-formula2-0954408912459161"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math2-0954408912459161"><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mo>⊗</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>IND</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula2-0954408912459161" xlink:href="10.1177_0954408912459161-eq2.tif"/></disp-formula>
where <inline-formula id="ilm11-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math11-0954408912459161"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⊗</mml:mo><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>X</mml:mi><mml:mo>∩</mml:mo><mml:mi>Y</mml:mi><mml:mo>:</mml:mo><mml:mo>∀</mml:mo><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mo>∀</mml:mo><mml:mi>Y</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>∩</mml:mo><mml:mi>Y</mml:mi><mml:mo>≠</mml:mo><mml:mi>Φ</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula></p>
<p>Let <italic>X </italic><inline-formula id="ilm12-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math12-0954408912459161"><mml:mrow><mml:mo>⊆</mml:mo></mml:mrow></mml:math></inline-formula> <italic>U</italic>, the <italic>P</italic>-lower approximation and <italic>P</italic>-upper approximation of set <italic>X</italic> can be defined as
<disp-formula id="disp-formula3-0954408912459161"><label>(3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math3-0954408912459161"><mml:mrow><mml:mi>P</mml:mi><mml:mtext>^- - -</mml:mtext><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:mi>X</mml:mi><mml:mo>≠</mml:mo><mml:mi>Φ</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula3-0954408912459161" xlink:href="10.1177_0954408912459161-eq3.tif"/></disp-formula>

<disp-formula id="disp-formula4-0954408912459161"><label>(4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math4-0954408912459161"><mml:mrow><mml:mi>P</mml:mi><mml:mtext>_- - -</mml:mtext><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⊆</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula4-0954408912459161" xlink:href="10.1177_0954408912459161-eq4.tif"/></disp-formula>
</p>
<p>Let <italic>P</italic> and <italic>Q</italic> be subsets of <italic>A</italic>, then the positive, negative, and boundary regions can be defined as
<disp-formula id="disp-formula5-0954408912459161"><label>(5)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math5-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>POS</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>∪</mml:mo></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mtext>_- - -</mml:mtext><mml:mi>X</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula5-0954408912459161" xlink:href="10.1177_0954408912459161-eq5.tif"/></disp-formula>

<disp-formula id="disp-formula6-0954408912459161"><label>(6)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math6-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>NEG</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mo>∪</mml:mo></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mtext>^- - -</mml:mtext><mml:mi>X</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula6-0954408912459161" xlink:href="10.1177_0954408912459161-eq6.tif"/></disp-formula>

<disp-formula id="disp-formula7-0954408912459161"><label>(7)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math7-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>BND</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>∪</mml:mo></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mtext>^- - -</mml:mtext><mml:mi>X</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mo>∪</mml:mo></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mtext>_- - -</mml:mtext><mml:mi>X</mml:mi></mml:mrow></mml:math><graphic alternate-form-of="disp-formula7-0954408912459161" xlink:href="10.1177_0954408912459161-eq7.tif"/></disp-formula>
</p>
<p>The positive region of the partition <italic>U</italic>/<italic>Q</italic> with respect to <italic>P</italic>, <inline-formula id="ilm13-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math13-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>POS</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, is the set of all objects of <italic>U</italic> that can be certainly classified to blocks of the partition <italic>U</italic>/<italic>Q</italic> by means of <italic>P</italic>. A set is rough (imprecise) if it has a non-empty boundary region.</p>
<p>An important issue in data analysis is discovering dependencies between attributes. Intuitively, a set of attributes <italic>Q</italic> depends totally on a set of attributes <italic>P</italic>, denoted as <italic>P </italic><inline-formula id="ilm14-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math14-0954408912459161"><mml:mrow><mml:mo>⇒</mml:mo></mml:mrow></mml:math></inline-formula> <italic>Q</italic>, if all values of the attributes from <italic>Q</italic> are uniquely determined by values of attributes from <italic>P</italic>. Dependency can be defined in the following way. Let <italic>Q</italic> and <italic>P</italic> be the subsets of <italic>A</italic>. We say that <italic>Q</italic> depends on <italic>P</italic> in a degree <italic>k</italic> (0 <inline-formula id="ilm15-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math15-0954408912459161"><mml:mrow><mml:mo>≤</mml:mo></mml:mrow></mml:math></inline-formula> <italic>k</italic> <inline-formula id="ilm16-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math16-0954408912459161"><mml:mrow><mml:mo>≤</mml:mo></mml:mrow></mml:math></inline-formula> 1), denoted as <italic>P </italic><inline-formula id="ilm17-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math17-0954408912459161"><mml:mrow><mml:mo>⇒</mml:mo></mml:mrow></mml:math></inline-formula> <italic>kQ</italic>, if
<disp-formula id="disp-formula8-0954408912459161"><label>(8)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math8-0954408912459161"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>POS</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic alternate-form-of="disp-formula8-0954408912459161" xlink:href="10.1177_0954408912459161-eq8.tif"/></disp-formula>
</p>
<p>If <italic>k</italic> = 1, <italic>Q</italic> depends totally on <italic>P</italic>, if 0 &lt; <italic>k</italic> &lt; 1, <italic>Q</italic> depends partially on <italic>P</italic>, and if <italic>k</italic>  =  0, then <italic>Q</italic> does not depend on <italic>P</italic>. In other words, <italic>Q</italic> depends totally (partially) on <italic>P</italic>, if all (some) objects of the universe <italic>U</italic> can be certainly classified to blocks of the partition <italic>U</italic>/<italic>Q</italic>, employing <italic>P</italic>.</p>
<p>In a decision system, the attribute set contains the condition attribute set <italic>C</italic> and decision attribute set <italic>D</italic>, i.e. <italic>A</italic> = <italic>C </italic>∪ <italic>D</italic>. The degree of dependency between condition and decision attributes, <inline-formula id="ilm18-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math18-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, is called the quality of approximation of classification, induced by the set of decision attributes.</p>
<p>The goal of attribute reduction is to remove redundant attributes in order to achieve the same quality of classification as the original. A reduction can be defined as a subset <italic>R</italic> of the conditional attribute set <italic>C</italic> such that <inline-formula id="ilm19-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math19-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> = <inline-formula id="ilm20-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math20-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. A given data set may have many attribute reductions; the set of all reductions is defined as
<disp-formula id="disp-formula9-0954408912459161"><label>(9)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math9-0954408912459161"><mml:mrow><mml:mtext>Re</mml:mtext><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>R</mml:mi><mml:mo>⊆</mml:mo><mml:mi>C</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∀</mml:mo><mml:mi>B</mml:mi><mml:mo>⊂</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula9-0954408912459161" xlink:href="10.1177_0954408912459161-eq9.tif"/></disp-formula>
</p>
<p>In rough set attribute reduction, a reduction with minimal set of attributes is searched for. An attempt is made to locate a single element of the reduction set <inline-formula id="ilm21-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math21-0954408912459161"><mml:mrow><mml:mtext>Re</mml:mtext><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>min</mml:mo></mml:mrow></mml:msub><mml:mo>⊆</mml:mo><mml:mtext>Re</mml:mtext><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula>
<disp-formula id="disp-formula10-0954408912459161"><label>(10)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math10-0954408912459161"><mml:mrow><mml:mtext>Re</mml:mtext><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>min</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi>R</mml:mi><mml:mo>∈</mml:mo><mml:mtext>Re</mml:mtext><mml:mi>d</mml:mi><mml:mo>|</mml:mo><mml:mo>∀</mml:mo><mml:mi>R</mml:mi><mml:mo>'</mml:mo><mml:mo>∈</mml:mo><mml:mtext>Re</mml:mtext><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mo>≤</mml:mo><mml:mo>|</mml:mo><mml:mi>R</mml:mi><mml:mo>'</mml:mo><mml:mo>|</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula10-0954408912459161" xlink:href="10.1177_0954408912459161-eq10.tif"/></disp-formula>
</p>
<p>The set of attributes which is common to all reductions is called the core, which is considered as the set of necessary attributes. In other words, the elements of a core cannot be eliminated. That is <inline-formula id="ilm22-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math22-0954408912459161"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mtext>Re</mml:mtext><mml:mi>d</mml:mi><mml:mo>-</mml:mo><mml:mo>min</mml:mo></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>α</mml:mi><mml:mo>≠</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mtext>Re</mml:mtext><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>min</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for any attribute <inline-formula id="ilm23-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math23-0954408912459161"><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mtext>Re</mml:mtext><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>min</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. In other words, any element of a core that is removed will result in the new set which does not belong to a Re<italic>d</italic>. Besides, the core is not unique; therefore, we can find at least one core.</p>
<p>The core is defined as:
<disp-formula id="disp-formula11-0954408912459161"><label>(11)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math11-0954408912459161"><mml:mrow><mml:mi>Core</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>∩</mml:mo></mml:mrow><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mtext>Re</mml:mtext><mml:mi>d</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula11-0954408912459161" xlink:href="10.1177_0954408912459161-eq11.tif"/></disp-formula>
</p>
<p>RST is more appropriate for those data sets which are too small to employ standard statistical methods. In addition, the other advantage of RST is that it does not require any preliminary or additional knowledge except for the supplied data. In the recent two decades, RST has rapidly established itself in many real-life applications. In our article, we applied RST with our proposed evolutionary algorithm to select the important attributes.</p>
</sec>
<sec id="sec7-0954408912459161"><title>Artificial neural network</title>
<p>ANN<sup><xref ref-type="bibr" rid="bibr10-0954408912459161">10</xref></sup> is an artificial intelligence technology with general application and great potential, which is composed of a large number of nerve cells. It offers significant support in terms of organizing, classifying, and summarizing data. It also helps to discern patterns among input data, requires few assumptions, and achieves a highly accurate solution. These characteristics of accuracy, adaptability, robustness, effectiveness, and efficiency make NN technology a potential alternative tool for recognition, classification, and FD. ANN usually consists of input, hidden, and output layers. The input layer is represented by circles and behaves as a buffer. Each neuron receives multiple inputs from other neurons, except the neurons in the input layer, in proportion to their connection weights and then generates a single output in accordance with an activation function. An activation function can be in a linear or non-linear form depending on the applications. Training the network is to adjust mainly the weights of the network using a different learning algorithm.</p>
<p>Training speed and real time of the network need be considered in order to satisfy commendable FD. There are some ANNs, such as back propagation neural network (BPNN), self-organizing map NN, Hopfield NN, RBFNN, etc. For FD, BPNN takes on the slow learning speed and easy local value. RBFNN belongs to multi-layer forward NNs, so RBFNN is selected to implement FD in this article. RBFNN is composed of the input, hidden, and output layers.<sup><xref ref-type="bibr" rid="bibr11-0954408912459161">11</xref></sup> The structure of RBFNN is shown in <xref ref-type="fig" rid="fig1-0954408912459161">Figure 1</xref>.
<fig id="fig1-0954408912459161" position="float"><label>Figure 1.</label><caption><p>RBFNN structure.</p>
<p>RBFNN: radial basis function neural network.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig1.tif"/>
</fig></p>
<p>From <xref ref-type="fig" rid="fig1-0954408912459161">Figure 1</xref>, while input learning vector of the NN is <inline-formula id="ilm24-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math24-0954408912459161"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> ∈ <inline-formula id="ilm25-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math25-0954408912459161"><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, the output of the neuron <italic>k</italic> can be expressed as
<disp-formula id="disp-formula12-0954408912459161"><label>(12)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math12-0954408912459161"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic alternate-form-of="disp-formula12-0954408912459161" xlink:href="10.1177_0954408912459161-eq12.tif"/></disp-formula>
</p>
<p>where <italic>n</italic>-dimensional input vector <inline-formula id="ilm26-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math26-0954408912459161"><mml:mrow><mml:mi>φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a basis function of the hidden layer that is the output of the neuron <italic>i</italic> in the hidden layer; <inline-formula id="ilm27-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math27-0954408912459161"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> an output vector; φ a RBF; <italic>c<sub>i</sub></italic> the center of the <italic>i</italic>th basis function, which has same dimensions as <italic>x</italic>; <inline-formula id="ilm28-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math28-0954408912459161"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> ∈ <inline-formula id="ilm29-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math29-0954408912459161"><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> the output weight matrix; <italic>m</italic> the number of the neurons in the input layer, <italic>n</italic> the number of neurons in the hidden layer; and <italic>k</italic> the number of the neurons in the output layer. The set Gauss function acts as a basis function, then
<disp-formula id="disp-formula13-0954408912459161"><label>(13)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math13-0954408912459161"><mml:mrow><mml:mi>φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi> </mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula13-0954408912459161" xlink:href="10.1177_0954408912459161-eq13.tif"/></disp-formula>
where <inline-formula id="ilm30-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math30-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the variance of the Gauss samples. Learning algorithm adopts a novel dynamic nearest neighbor-clustering algorithm. The algorithm yields the least nodes and has a high learning speed. The key problem of RBFNN is to confirm the number of hidden nodes, locations and width of the corresponding center nodes. When they are confirmed, RBFNN will become linear from the input layer to the output one. At the same time, the output weight vector can be obtained using the least-squares method.</p>
</sec>
<sec id="sec8-0954408912459161"><title>Genetic algorithms</title>
<p>GAs<sup><xref ref-type="bibr" rid="bibr12-0954408912459161">12</xref></sup> are a kind of stochastic global search algorithm which solves complex problems by imitating processes of natural evolution. Based on survival of the fittest and reproduction, GAs exploit continually newer and better solutions without any pre-assumptions, such as continuity and unimodality. GAs have been successfully applied in many complex optimization problems, and they show merits over traditional optimization methods, especially in a system which has multiple local optimum solutions. GAs evolve a population of candidate solutions. Each solution is usually coded as a binary string called a chromosome.<sup><xref ref-type="bibr" rid="bibr13-0954408912459161">13</xref></sup> The fitness of each chromosome is evaluated using a performance function after the chromosome has been decoded. Upon completion of the evaluation, a biased roulette wheel is used to select randomly the pairs of better chromosomes to undergo genetic operations, crossover, and mutation. The newly produced chromosomes turn out to be stronger than the weaker ones from the previous generation and they should replace these weaker chromosomes. This evolution process continues executing until the stopping criteria are reached. GAs are composed of encoded mechanism, fitness function, genetic operators, control parameters, etc.<sup><xref ref-type="bibr" rid="bibr14-0954408912459161">14</xref></sup> The computation flow is shown in <xref ref-type="fig" rid="fig2-0954408912459161">Figure 2</xref>.
<fig id="fig2-0954408912459161" position="float"><label>Figure 2.</label><caption><p>Flow chart of GAs.</p>
<p>GAs: genetic algorithms.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig2.tif"/>
</fig></p>
<p>/*</p>
<p>P(t) denotes a certain era colony, t is the current evolution algebra.</p>
<p>Best denotes the current optimization solving in finding results.</p>
<p>*/</p>
<p>Procedure GA</p>
<p><bold>begin</bold></p>
<p>t ← 0</p>
<p> initialize (P(t));evaluate(P(t));keep_best(P(t));</p>
<p><bold> while</bold>(Do not meet ending condition) <bold>do</bold></p>
<p><bold> begin</bold></p>
<p> <bold> </bold>P(t) ← selection(P(t));</p>
<p><bold>  </bold>P(t) ← crossover(P(t));</p>
<p><bold>  </bold>P(t) ← mutation(P(t));</p>
<p><bold>  </bold>t ← t + 1;</p>
<p><bold>  </bold>P(t) ← P(t-1));</p>
<p><bold>  </bold>evaluate (P(t));</p>
<p><bold>  if</bold> (the optimized fitness value of P(t) &gt; Best fitness value)</p>
<p><bold>   </bold>replace(Best);</p>
<p><bold>   end if</bold></p>
<p><bold>  end</bold></p>
<p><bold>end</bold></p>
</sec>
</sec>
<sec id="sec9-0954408912459161"><title>Combining RBFNN and GAs</title>
<p>Some methods by combining GAs with RBFNN have been reported in recent studies.<sup><xref ref-type="bibr" rid="bibr15-0954408912459161">15</xref><xref ref-type="bibr" rid="bibr16-0954408912459161"/>–<xref ref-type="bibr" rid="bibr17-0954408912459161">17</xref></sup> In these approaches, GAs or NN play a primary role in the problem solver. In this article, GAs are used to train RBFNN in order to obtain the optimized RBF network model. GAs are a kind of operation in the colony, operating objects are all individuals in the colony and make a new generation colony by selection, crossover, and mutation. GAs are used to optimize the parameters, structure, and learning rule of RBFNN, which provides a new way for training RBFNN. As GAs adopt the colony-search strategy, which makes a little impact for selecting the cluster result of the initial cluster center, it can improve the performance of RBFNN. Also, the training process of the RBFNN is divided into two steps for completion. That is to say, determine weight <italic>w</italic><sub>1</sub> between the input and hidden layers and weight <italic>w</italic><sub>2</sub> between hidden and output layers. Before training RBFNN, the numerical value of the vector <italic>x</italic> must be ascertained in order to solve for weights <italic>w</italic><sub>1</sub>, weights <italic>w</italic><sub>2</sub>, threshold <italic>b</italic><sub>1</sub>, and threshold <italic>b</italic><sub>2</sub> (when the number of hidden layer unit equals the number of input vectors, <italic>b</italic><sub>2</sub>  =  0). In this process, the key is to make the number of hidden layer neurons equal to one at first; the number of the network hidden neurons is automatically increased in the course of the training network until the mean square error meets the precision or the number of neurons reach the threshold. The flow of combining RBFNN and GAs is shown in <xref ref-type="fig" rid="fig3-0954408912459161">Figure 3</xref>.
<fig id="fig3-0954408912459161" position="float"><label>Figure 3.</label><caption><p>The flow chart of a combination of RBFNN and GAs.</p>
<p>RBFNN: radial basis function neural network; GAs: genetic algorithms.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig3.tif"/>
</fig></p>
<p>From <xref ref-type="fig" rid="fig3-0954408912459161">Figure 3</xref>, the steps of training network are shown as follows:
<list id="list1-0954408912459161" list-type="order">
<list-item><p>Genetic encoding of RBFNN. Use the sort number of the cluster as gene value to construct chromosome and initial population.</p></list-item>
<list-item><p>Construct fitness function. Take the reciprocal of the total distortion
<disp-formula id="disp-formula14-0954408912459161"><label>(14)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math14-0954408912459161"><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>[</mml:mo></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn> </mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo> </mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula14-0954408912459161" xlink:href="10.1177_0954408912459161-eq14.tif"/></disp-formula>
</p></list-item>
<list-item><p>Genetic operation. Take selection, crossover, and mutation operations until this algorithm reaches convergence.</p></list-item>
<list-item><p>Compute the center and width of RBFNN. Each class of genetic clustering algorithm is considered as the hidden nodes. Respectively, the center (<italic>c<sub>j</sub></italic>) and width (<inline-formula id="ilm31-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math31-0954408912459161"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi> </mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>) of RBFNN are computed according to the following formula
<disp-formula id="disp-formula15-0954408912459161"><label>(15)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math15-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic alternate-form-of="disp-formula15-0954408912459161" xlink:href="10.1177_0954408912459161-eq15.tif"/></disp-formula>

<disp-formula id="disp-formula16-0954408912459161"><label>(16)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math16-0954408912459161"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi> </mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><graphic alternate-form-of="disp-formula16-0954408912459161" xlink:href="10.1177_0954408912459161-eq16.tif"/></disp-formula>
</p></list-item>
<list-item><p>Adjust the weights between the hidden and output layers.</p></list-item>
</list></p>
</sec>
<sec id="sec10-0954408912459161"><title>Hybrid intelligence FD method in a complicated CNC system</title>
<sec id="sec11-0954408912459161"><title>Fusion thoughts</title>
<p>In the past decades, various FD techniques have been proposed, such as Fuzzy Theory,<sup><xref ref-type="bibr" rid="bibr18-0954408912459161">18</xref></sup> ANN,<sup><xref ref-type="bibr" rid="bibr19-0954408912459161">19</xref></sup> expert system,<sup><xref ref-type="bibr" rid="bibr20-0954408912459161">20</xref></sup> RST,<sup><xref ref-type="bibr" rid="bibr21-0954408912459161">21</xref></sup> GAs,<sup><xref ref-type="bibr" rid="bibr22-0954408912459161">22</xref></sup> and other new algorithms.<sup><xref ref-type="bibr" rid="bibr23-0954408912459161">23</xref></sup> However, each method possesses a stronger diagnosing ability for small-scale information system. For the large-scale complicated information system, each method still cannot effectively achieve FD. In particular, while the related evidences are incomplete or the relevant conclusions are dubious, these problems would become more complicated. RST can effectively elucidate the significance of different attributes in knowledge expression system and reduction of knowledge expression space. However, it is often helpless when it is used to deal with incomplete data. In order to simplify the ANN structure and improve its anti-interference ability, RST is used to act as the pretreatment cell of ANN and mine useful knowledge from the diagnosis knowledge base. GAs can optimize the structure and parameters of an ANN. Clearly, the synthesized method has better characteristics than single ANN or GA or RST. So, we propose a novel integrated artificial intelligent hybrid algorithm based on combining ANN, GAs, and RST for vibration FD in a complicated CNC system. In the proposed hybrid algorithm, RST is used to mine the rules. When their ‘confidence’ and ‘support’ satisfy a preset criterion, these rules are used as a diagnosis knowledge base in order to offer directly the FD service. The ANN integrated with GAs is used to diagnose these which cannot be diagnosed by a rough set. The process uses seven trained NNs, which have different learning rates, middle hidden layer numbers, and correlative training parameters, to diagnose the faults.</p>
</sec>
<sec id="sec12-0954408912459161"><title>Hybrid intelligence FD method in the complicated CNC system</title>
<p>The FD in the complicated CNC system is to obtain fault symptom information from the equipment and process by the faulty reasoning. The framework of hybrid intelligence vibration FD in the complicated CNC system is shown in <xref ref-type="fig" rid="fig4-0954408912459161">Figure 4</xref>.
<fig id="fig4-0954408912459161" position="float"><label>Figure 4.</label><caption><p>Intelligent FD model in a complicated CNC system.</p>
<p>FD: fault diagnosis; CNC: computer numerical control.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig4.tif"/>
</fig></p>
<p>The detailed flow of hybrid intelligence FD method in the complicated CNC system is shown in <xref ref-type="fig" rid="fig5-0954408912459161">Figure 5</xref>.
<fig id="fig5-0954408912459161" position="float"><label>Figure 5.</label><caption><p>Working flow of hybrid intelligence FD method in a complicated CNC system.</p>
<p>FD: fault diagnosis; CNC: computer numerical control.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig5.tif"/>
</fig></p>
<p>From <xref ref-type="fig" rid="fig5-0954408912459161">Figure 5</xref>, the specific steps of hybrid intelligence FD method in the complicated CNC system are shown as follows:</p>
<p><bold>Step 1</bold> Input the original sample data.</p>
<p>Extract randomly the historical fault information of the complicated system from the relational database.</p>
<p><bold>Step 2</bold> Pretreatment data.</p>
<p>Construct relational data model of the complicated system in order to establish two-dimensional decision table of original fault information. Data pretreatment is carried out by some data processing in order to improve the abstract generalization of knowledge radix, reduce the physical dimension of knowledge template, and provide the involved semi-finished data set with the discovering task of mining kernel knowledge. There are some main processing methods:
<list id="list3-0954408912459161" list-type="order">
<list-item><p>Data integration. It combines the isomerous data in multi-database running environment and solves the semantic model. It mainly involves processing problem conversion of data class, selection, collision and disaccord, etc.</p></list-item>
<list-item><p>Data completion. It removes noise data, irrespective data, null data, and omitted data in the data set. Data completion mainly involves processing of repeated data and missing data, and finishes some conversions of data types.</p></list-item>
<list-item><p>Data transformation Use dimension transform or conversion mode to reduce the number of the effective variables or find out the data invariant, including the operation of specification, conclusion, switching, circumrotation, projection, etc.</p></list-item>
<list-item><p>Data reduction. Ask for the used characteristics of the expressed data depending on the discovering goal and reduce data scale. Condense the data quantity keeping the most self-contained degree. Attribute selection and record sample are the two main approaches.</p></list-item>
</list></p>
<p><bold>Step 3</bold> Discretization of continuous attributes.</p>
<p>From the above section, we have got the basic theory of RST and know that RST is an excellent knowledge mining tool. Unfortunately, there exists a crucial issue in the application of RST, that is, RST cannot deal with the continuous attributes, which is the disadvantage of this method and limits its application range.</p>
<p>To deal with this issue, many discretization methods have been put forward in the past few years. Existing methods can be classified into the following three different axes: global versus local, supervised versus unsupervised, and static versus dynamic. The unsupervised discretization includes methods based on the equal-width-intervals, equal-frequency-intervals, statistical knowledge, etc. These methods are simple and easy to operate, while they do not use the classification information about decision attributes. Supervised discretization includes methods based on the information entropy, fuzzy cluster, and GAs; these methods are more complicated, while they consider the classification information about the decision attributes, which achieves satisfactory discretization results.</p>
<p>From these methods, the discretization process of feature vector may be condensed to a division that the attribute value is divided into limited spaces and each space corresponds to a discrete value. Through this division, a number of demarcation points are set up in the value domain of attribute; moreover, different numbers and positions of demarcation points play a different role in the final application. For example, numerous demarcation points may bring forth a finer division, which will describe the object more accurately, but often produce a feature vector with higher dimensions and bring a lot of redundant information, thereby increasing the computational complicatedity and affecting their cognition speed. Conversely, fewer demarcation points may produce a coarse division, which will lead to the increase of incompatible information, affecting the accuracy of the recognition results. Thus, there arises a problem of how to determine the number and position of the demarcation points in the discretization of feature vectors.</p>
<p>Because GAs have the characteristics of connotative parallel and powerful full-search ability, they are used to optimize the selected breakpoints in the decision table and construct an algorithm of continuous attribute discretization. The flow of discretization is shown in <xref ref-type="fig" rid="fig6-0954408912459161">Figure 6</xref>.
<fig id="fig6-0954408912459161" position="float"><label>Figure 6.</label><caption><p>The specific steps of discretization of continuous attributes.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig6.tif"/>
</fig></p>
<p>From <xref ref-type="fig" rid="fig6-0954408912459161">Figure 6</xref>, the specific steps of continuous attribute discretization are shown as follows:
<list id="list5-0954408912459161" list-type="order">
<list-item><p>Generate initial breakpoints of decision table, which is encoded into binary.</p></list-item>
<list-item><p>According to the complicated nature of the problem solved, the value of population <italic>m</italic> is 50 to 100.</p></list-item>
<list-item><p>Decode chromosome in population to obtain breakpoint set of each chromosome expression. Compute the value of the fitness function.</p></list-item>
<list-item><p>The best individual in the population is copied into the next population, and then parental population will make genetic operations of selection, crossover, and mutation in order to propagate the next new population.</p></list-item>
<list-item><p>If the result reaches the enactment multiplication threshold, the best chromosome is returned and the optimal breakpoint set is also obtained. The algorithm will end. Otherwise, return to Step 3 to continue the next multiplication.</p></list-item>
</list></p>
<p><bold>Step 4</bold> The attribute reduction. Since people always hope to get fewer condition attributes of reduction result, reduction is used to remove the unnecessary condition attributes and get the concise decision rule. Attribute reduction algorithm based on RST mainly includes attribute reduction on discernibility matrix and logic operation, induction attribute reduction algorithm, etc. These algorithms do not adequately think over the specialty of knowledge in the data domain and flexibility. In this article, a kind of attribute significance reduction algorithm based on RST is used to reduce the decision table. This algorithm is described as follows:
<list id="list7-0954408912459161" list-type="alpha-upper">
<list-item><p>Calculate the relative core <italic>C</italic><sub>core</sub>(<italic>C</italic>, <italic>D</italic>)</p></list-item>
<list-item><p>Calculate <italic>g</italic> the degree of dependency <italic>γ</italic>(<italic>C</italic>, <italic>D</italic>)</p></list-item>
<list-item><p><italic>R</italic><sub>red </sub>←<sub> </sub><italic>C</italic><sub>core</sub></p></list-item>
<list-item><p>For arbitrary attribute <italic>a<sub>i</sub><sub> </sub></italic>∈ <italic>C</italic> − <italic>R</italic><sub>red.</sub></p></list-item>
<list-item><p>Calculate the significance <italic>S</italic><sub>SGF</sub> (<italic>a</italic>, <italic>R</italic><sub>red</sub>, <italic>D</italic>)</p></list-item>
<list-item><p><italic>R</italic><sub>red </sub>←<sub> </sub><italic>R</italic><sub>red</sub>  +  <italic>a,</italic> where
<disp-formula id="disp-formula17-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math17-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>SGF</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>red</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>ai</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi><mml:mo>-</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>red</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>SGF</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>red</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula17-0954408912459161" xlink:href="10.1177_0954408912459161-eq17.tif"/></disp-formula>
</p></list-item>
<list-item><p>Calculate the degree of dependency <italic>γ</italic> (<italic>R</italic><sub>red</sub>, <italic>D</italic>)</p></list-item>
<list-item><p>If <italic>γ</italic>(<italic>R</italic><sub>red</sub>, <italic>D</italic>)  =  <italic>γ</italic>(<italic>C</italic>, <italic>D</italic>)</p></list-item>
<list-item><p>Return <italic>R</italic><sub>red</sub>; break the cycle; or loop <bold>E</bold></p></list-item>
<list-item><p>According to the obtained reduction, the cases of the same attribute values are combined</p></list-item>
</list></p>
<p>We use formulae (17) and (18) to compute the importance degree of attribute
<disp-formula id="disp-formula18-0954408912459161"><label>(17)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math18-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>card</mml:mtext><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mtext>pos</mml:mtext></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mtext>card</mml:mtext><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula18-0954408912459161" xlink:href="10.1177_0954408912459161-eq18.tif"/></disp-formula>

<disp-formula id="disp-formula19-0954408912459161"><label>(18)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math19-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>card</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mtext>pos</mml:mtext></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">/</mml:mo><mml:mtext>card</mml:mtext><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula19-0954408912459161" xlink:href="10.1177_0954408912459161-eq19.tif"/></disp-formula>
</p>
<p><bold>Step 5</bold> Start GAs to generate an initial population and optimize RBFNN. The last, GRN model is obtained.</p>
<p><bold>Step 6</bold> Obtain the least rule set by reduction using rough set which inputs the GRN model to train in order to get the RGRN model</p>
<p><bold>Step 7</bold> Determine the diagnosis error by RGRN model regarding whether to meet the requirements; otherwise, select other reduction set and return to <bold>Step 4</bold>.</p>
<p><bold>Step 8</bold> Using the trained RGRN model to diagnose faults of the waiting fault information in order to obtain the diagnosis result.</p>
</sec>
</sec>
<sec id="sec13-0954408912459161"><title>Experiment simulation</title>
<p>In this section, we prove the accuracy and performance of the vulnerability assessment techniques described in the previous section based on the motor variety in the complicated CNC system. Use a motor subsystem to make a vibration FD for example. Due to a lot of reasons, such as complicated system, sensor own fault, signal gathering difficulty, data transmission error, processing error, etc., some gathered data are missed. In this article, <italic>U</italic> is the universe and <italic>a</italic><sub> </sub>–<sub> </sub><italic>e</italic> the condition attributes, respectively, and they express the amplitude of frequency energy of the domain signature spectrum of the motor vibration signal &lt;0.4<italic>f</italic>, 0.4–0.5<italic>f</italic>, 1<italic>f</italic>, 2<italic>f</italic>, ≥3<italic>f</italic> (<italic>f</italic> is the vibration frequency). The term ‘<italic>h</italic>’ is the decision attribute, which indicates the different motor faults in the complicated CNC system. The value of ‘<italic>h</italic>’ is 1, 2, 3, corresponding to the fault, such as oil-film whipping, imbalance, and misalignment. Some part of the data is used for research. The incomplete data are classed to obtain the diagnosis decision rule set. The decision table of incomplete vibration FD has normal processing, as presented in <xref ref-type="table" rid="table1-0954408912459161">Table 1</xref>.
<table-wrap id="table1-0954408912459161" position="float"><label>Table 1.</label><caption><p>Decision table of incomplete vibration FD.</p></caption>
<graphic alternate-form-of="table1-0954408912459161" xlink:href="10.1177_0954408912459161-table1.tif"/>
<table frame="hsides"><thead align="left">
<tr><th><italic>U</italic></th>
<th><italic>a</italic></th>
<th><italic>b</italic></th>
<th><italic>c</italic></th>
<th><italic>d</italic></th>
<th><italic>e</italic></th>
<th><italic>h</italic></th>
</tr></thead>
<tbody align="left">
<tr>
<td>1</td>
<td>0.052</td>
<td>0.783</td>
<td>0.225</td>
<td>*</td>
<td>0.013</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>0.232</td>
<td>0.975</td>
<td>0.314</td>
<td>0.056</td>
<td>*</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>0.161</td>
<td>*</td>
<td>0.285</td>
<td>0.023</td>
<td>0.016</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>0.028</td>
<td>0.061</td>
<td>0.980</td>
<td>*</td>
<td>0.057</td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>0.045</td>
<td>0.022</td>
<td>*</td>
<td>0.316</td>
<td>0.065</td>
<td>2</td>
</tr>
<tr>
<td>6</td>
<td>0.010</td>
<td>0.054</td>
<td>0.875</td>
<td>0.183</td>
<td>*</td>
<td>2</td>
</tr>
<tr>
<td>7</td>
<td>0.033</td>
<td>0.037</td>
<td>0.386</td>
<td>0.531</td>
<td>0.230</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>*</td>
<td>0.023</td>
<td>*</td>
<td>0.458</td>
<td>0.103</td>
<td>3</td>
</tr>
<tr>
<td>9</td>
<td>0.012</td>
<td>*</td>
<td>0.427</td>
<td>0.496</td>
<td>0.175</td>
<td>3</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0954408912459161">
<p>FD: fault diagnosis<sc>.</sc></p></fn></table-wrap-foot>
</table-wrap></p>
<p>First of all, combination and the condition supplement algorithm was used to make the reasonable supplement for the missed data. GAs are used to discretize continuous attributes. The discrete result of FD is presented in <xref ref-type="table" rid="table2-0954408912459161">Table 2</xref>.
<table-wrap id="table2-0954408912459161" position="float"><label>Table 2.</label><caption><p>Discretization vibration FD decision table.</p></caption>
<graphic alternate-form-of="table2-0954408912459161" xlink:href="10.1177_0954408912459161-table2.tif"/>
<table frame="hsides"><thead align="left">
<tr><th><italic>U</italic></th>
<th><italic>a</italic></th>
<th><italic>b</italic></th>
<th><italic>c</italic></th>
<th><italic>d</italic></th>
<th><italic>e</italic></th>
<th><italic>h</italic></th>
</tr></thead>
<tbody align="left">
<tr>
<td>1</td>
<td>1</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>3</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>7</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>9</td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>3</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn2-0954408912459161">
<p>FD: fault diagnosis</p></fn></table-wrap-foot>
</table-wrap></p>
<p>According to formulae (<italic>r<sub>C</sub></italic>(<italic>D</italic>)  =  card(pos<italic><sub>C</sub></italic>(<italic>D</italic>))/card (<italic>U</italic>)) and (<italic>r<sub>C</sub></italic><sub> − </sub><italic><sub>a</sub></italic>(<italic>D</italic>)  =  card(pos<italic><sub>C</sub></italic><sub> − </sub><italic><sub>a</sub></italic>(<italic>D</italic>))/card (<italic>U</italic>)), we make knowledge reduction for the discrete decision table (<xref ref-type="table" rid="table3-0954408912459161">Table 3</xref>), computing processing is shown below:
<disp-formula id="disp-formula20-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="math20-0954408912459161"><mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>ind</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>8</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>ind</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>abcd</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>8</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>ind</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>abce</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>8</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>ind</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>abde</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>ind</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>acde</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>8</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>/</mml:mo><mml:mi>ind</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>bcde</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>8</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>9</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>9</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi/><mml:mrow/></mml:msub></mml:mrow></mml:msub><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>b</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi/><mml:mrow/></mml:msub></mml:mrow></mml:msub><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>c</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi/><mml:mrow/></mml:msub></mml:mrow></mml:msub><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>d</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mo>{</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mrow><mml:mo> </mml:mo><mml:mo>}</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>pos</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>card</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mtext>-</mml:mtext><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo> </mml:mo><mml:mo>(</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mn>7</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mrow></mml:math><graphic alternate-form-of="disp-formula20-0954408912459161" xlink:href="10.1177_0954408912459161-eq20.tif"/></disp-formula>

<table-wrap id="table3-0954408912459161" position="float"><label>Table 3.</label><caption><p>Reduction vibration FD decision table.</p></caption>
<graphic alternate-form-of="table3-0954408912459161" xlink:href="10.1177_0954408912459161-table3.tif"/>
<table frame="hsides"><thead align="left">
<tr><th><italic>U</italic></th>
<th><italic>a</italic></th>
<th><italic>c</italic></th>
<th><italic>d</italic></th>
<th><italic>e</italic></th>
<th><italic>h</italic></th>
</tr></thead>
<tbody align="left">
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>3</td>
<td>3</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>7</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>9</td>
<td>1</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>3</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn>
<p>FD: fault diagnosis</p></fn></table-wrap-foot>
</table-wrap></p>
<p>According to the computation of the original decision table, we obtain the computation results which have analyzed the computed results. Attribute set {<italic>a</italic>, <italic>c</italic>, <italic>d</italic>, <italic>e</italic>} is important to the original decision table. We may prove that {<italic>a</italic>, <italic>c</italic>, <italic>d</italic>, <italic>e</italic>} is the minimal reduction attribute set of the decision table. It is shown that for decision attributes, {<italic>a</italic>, <italic>c</italic>, <italic>d</italic>, <italic>e</italic>} keeps the classification ability of the five attributes, and {<italic>a</italic>, <italic>c</italic>, <italic>d</italic>, <italic>e</italic>} is the essential attribute for the decision system. We can delete the redundant attribute {<italic>b</italic>} from <xref ref-type="table" rid="table2-0954408912459161">Table 2</xref> to obtain a reduction expression of the original data. We reorganize the reduction decision table, merge the same rule, and delete the redundant rule. Finally, we obtain the minimum rule set, which is regarded as the input of the GRN model.</p>
<p>Train the GRN network model: GAs initial colony Pop  =  60, §  =  5. The accuracy requirement of the RBF algorithm is error  =  0.001, learning speed 1 s  =  0.01, training times: epochs  =  50,000. In the environment of Matlab 2009, we use the GRN network model in the repeated network study and the simulation experiment by learning samples. The training target curve of GRN network is obtained, as shown in <xref ref-type="fig" rid="fig7-0954408912459161">Figure 7</xref>.
<fig id="fig7-0954408912459161" position="float"><label>Figure 7.</label><caption><p>The training target error curve of the RGRN model.</p>
<p>RGRN: rough set, genetic algorithms, and radial basic function neural network.</p></caption><graphic xlink:href="10.1177_0954408912459161-fig7.tif"/>
</fig></p>
<p>As can be seen in <xref ref-type="fig" rid="fig7-0954408912459161">Figure 7</xref>, this is a learning error curve of the RGRN method. From <xref ref-type="fig" rid="fig7-0954408912459161">Figure 7</xref>, it can be observed that the mean squared error is gradually decreasing with the increasing iteration times. Also, the minimal mean squared error is 0.001. So, the RGRN method takes on certain generalization ability (robustness), less circulation calculation, steady training process, quick training speed, and precise training method. We discover that the training time of RSGRN method is longer than GAs or RBFNN. But the training time of RGRN method is shorter than the total training time of GAs and RBFNN. That is to say, <inline-formula id="ilm32-0954408912459161"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline" id="mml-math32-0954408912459161"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mtext>GAs</mml:mtext></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>or</mml:mtext><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mtext>RBFNN</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mtext>RGRN</mml:mtext></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mtext>GAs</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mtext>RBFNN</mml:mtext></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p>
<p>In order to test the FD ability of the RGRN method, we collect the diagnostic information {(0.022, *, 0.746, 0.124, 0.021), (0.018, 0.059, 0.488, *, 0.313)} which is to be dealt with by the completeness and RST and input of the RGRN network model to make the FD. We obtain the result of FD: the first set of data fault <italic>g</italic>  =  2 (imbalance fault) and the second set of data fault <italic>g</italic>  =  3 (misalignment fault), the same as the actual fault. Simulation experiments indicate that our proposed RGRN method is effective and accurate for FD in complicated CNC systems.</p>
</sec>
<sec id="sec14-0954408912459161" sec-type="conclusions"><title>Conclusion</title>
<p>In this article, GAs and NN integrated with rough set weighted fusion algorithm for FD in the complicated CNC system is proposed. The proposed FD model incorporates the excellences of rough set, RBFNN, and GAs and overcomes the disadvantages of the three. The diagnostic efficiency and correctness are improved in the complicated CNC system. In the proposed RGRN model, hybrid clustering and GAs could discretize, and rough set can reduce and delete the redundant data in the collected sample data and obtain the reduction attribute as pretreatment of the GRN input layer’s node information. The reduction result can reduce the number of input nodes in RBFNN and solve problems where the scale of network that is too large and the speed of classification recognition is too slow and other problems. Sequentially, the RBFNN structure and network is optimized using GAs. Training time will be reduced and network noise immunity will be enhanced. The proposed RGRN method can effectively eliminate false and omit alarm of FD and offer FD technology with a new thought and method. The integrated RGRN method also can have a good diagnosis ability. The hybrid mechanism has a good classified diagnosis ability. The proposed RGRN method can be used not only for FD and analysis for motor, but also in the signal recognition field. It has a better spread application foreground.</p>
</sec>
</body>
<back><ack><title>Acknowledgment</title>
<p>The authors thank all the reviewers for their constructive comments.</p></ack>
<sec id="sec15-0954408912459161"><title>Funding</title>
<p>This work was supported by the Open Project Program of the Traction Power State Key Laboratory of Southwest Jiaotong University (grant no. TPL1203), the Visiting Scholarship of the State Key Laboratory of Power Transmission Equipment &amp; System Security and New Technology (Chongqing University) (grant no. 2007DA10512711406), the National Natural Science Foundation of China (grant no. 51175054), the National High Technology Research and Development Program of China (863 Program) (grant no. 2012AA040912), the Open Project Program of the Key Laboratory of Intelligent Computing &amp; Signal Processing, Ministry of Education (Anhui University), China, the Open Project Program of the Artificial Intelligence Key Laboratory of Sichuan Province (Sichuan University of Science and Engineering), China (grant no. 2010RZ004), the Open Project Program of the Key Laboratory of Advanced Design and Intelligent Computing (Dalian University), Ministry of Education, China (grant no. ADIC2010008), and the Open Project Program of the Key Laboratory of Numerical Simulation in the Sichuan Provincial College (Neijiang Normal University), China (grant no. 2011SZFZ001).</p>
</sec>
<ref-list><title>References</title>
<ref id="bibr1-0954408912459161"><label>1</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>JD</given-names></name><name><surname>Liu</surname><given-names>CH</given-names></name></person-group>. <article-title>An expert system for fault diagnosis in internal combustion engines using wavelet packet transform and neural network</article-title>. <source>Expert Syst Appl</source> <year>2009</year>; <volume>36</volume>(<issue>3</issue>): <fpage>4278</fpage>–<lpage>4286</lpage>.</citation></ref>
<ref id="bibr2-0954408912459161"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>CC</given-names></name><name><surname>Gu</surname><given-names>XD</given-names></name><name><surname>Wang</surname><given-names>YY</given-names></name></person-group>. <article-title>Fault diagnosis of power electronic system based on fault gradation and neural network group</article-title>. <source>Neurocomputing</source> <year>2009</year>; <volume>72</volume>(<issue>13–15</issue>): <fpage>2909</fpage>–<lpage>2914</lpage>.</citation></ref>
<ref id="bibr3-0954408912459161"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>García</surname><given-names>S</given-names></name><name><surname>Cano</surname><given-names>JR</given-names></name><name><surname>Bernadó-Mansilla</surname><given-names>E</given-names></name><etal/></person-group>. <article-title>Diagnose effective evolutionary prototype selection using an overlapping measure</article-title>. <source>Int J Pattern Recognit</source> <year>2009</year>; <volume>23</volume>(<issue>8</issue>): <fpage>1527</fpage>–<lpage>1548</lpage>.</citation></ref>
<ref id="bibr4-0954408912459161"><label>4</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>ZQ</given-names></name><name><surname>Zhu</surname><given-names>QX</given-names></name></person-group>. <article-title>Rough set-based heuristic hybrid recognizer and its application in fault diagnosis</article-title>. <source>Expert Syst Appl</source> <year>2009</year>; <volume>36</volume>(<issue>2</issue>): <fpage>2711</fpage>–<lpage>2718</lpage>.</citation></ref>
<ref id="bibr5-0954408912459161"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marzena</surname><given-names>K</given-names></name></person-group>. <article-title>Rough set approach to incomplete information systems</article-title>. <source>Inf Sci</source> <year>1998</year>; <volume>112</volume>(<issue>1–4</issue>): <fpage>39</fpage>–<lpage>49</lpage>.</citation></ref>
<ref id="bibr6-0954408912459161"><label>6</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marzena</surname><given-names>K</given-names></name></person-group>. <article-title>Rules in incomplete information systems</article-title>. <source>Inf Sci</source> <year>1999</year>; <volume>113</volume>(<issue>3–4</issue>): <fpage>271</fpage>–<lpage>292</lpage>.</citation></ref>
<ref id="bibr7-0954408912459161"><label>7</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ekinci</surname><given-names>S</given-names></name><name><surname>Celebi</surname><given-names>UB</given-names></name><name><surname>Bal</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>Predictions of oil/chemical tanker main design parameters using computational intelligence</article-title>. <source>Appl Soft Comput</source> <year>2011</year>; <volume>11</volume>(<issue>2</issue>): <fpage>2356</fpage>–<lpage>2366</lpage>.</citation></ref>
<ref id="bibr8-0954408912459161"><label>8</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pawlak</surname><given-names>Z</given-names></name></person-group>. <article-title>Rough sets</article-title>. <source>Int J Comput Inf Sci</source> <year>1982</year>; <volume>11</volume>(<issue>5</issue>): <fpage>341</fpage>–<lpage>356</lpage>.</citation></ref>
<ref id="bibr9-0954408912459161"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>W</given-names></name><name><surname>Yang</surname><given-names>XH</given-names></name><name><surname>Zou</surname><given-names>L</given-names></name><etal/></person-group>. <article-title>An efficient fusion approach to rule extraction based on rough set theory and particle swarm optimization and its application</article-title>. <source>Proc IMechE Part I: J Syst Control Eng</source> <year>2012</year>; <volume>226</volume>(<issue>7</issue>): <fpage>904</fpage>–<lpage>913</lpage>.</citation></ref>
<ref id="bibr10-0954408912459161"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Setiono</surname><given-names>HR</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name></person-group>. <article-title>Effective data-mining using neural networks</article-title>. <source>IEEE Trans Knowl Data Eng</source> <year>1996</year>; <volume>8</volume>(<issue>6</issue>): <fpage>957</fpage>–<lpage>961</lpage>.</citation></ref>
<ref id="bibr11-0954408912459161"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wing</surname><given-names>WYN</given-names></name><name><surname>Daniel</surname><given-names>SY</given-names></name><name><surname>Michael</surname><given-names>F</given-names></name><etal/></person-group>. <article-title>Feature selection using localized generalization error for supervised classification problems using RBFNN</article-title>. <source>Pattern Recognit</source> <year>2008</year>; <volume>41</volume>(<issue>12</issue>): <fpage>3706</fpage>–<lpage>3719</lpage>.</citation></ref>
<ref id="bibr12-0954408912459161"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>MLD</given-names></name><name><surname>Nandi</surname><given-names>AK</given-names></name></person-group>. <article-title>Automatic digital modulation recognition using artificial neural network and genetic algorithm</article-title>. <source>Sig Proc</source> <year>2004</year>; <volume>84</volume>(<issue>2</issue>): <fpage>351</fpage>–<lpage>365</lpage>.</citation></ref>
<ref id="bibr13-0954408912459161"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>R</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>A novel parallel hybrid intelligence optimization algorithm for function approximation problem</article-title>. <source>Comput Math Appl</source> <year>2012</year>; <volume>63</volume>(<issue>1</issue>): <fpage>325</fpage>–<lpage>336</lpage>.</citation></ref>
<ref id="bibr14-0954408912459161"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Todorovski</surname><given-names>M</given-names></name><name><surname>Rajicic</surname><given-names>D</given-names></name></person-group>. <article-title>An initialization procedure in solving optimal power flow by genetic algorithm</article-title>. <source>IEEE Trans Power Syst</source> <year>2006</year>; <volume>21</volume>(<issue>2</issue>): <fpage>480</fpage>–<lpage>487</lpage>.</citation></ref>
<ref id="bibr15-0954408912459161"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nameer</surname><given-names>NEE</given-names></name><name><surname>Riadh</surname><given-names>HAR</given-names></name></person-group>. <article-title>An intelligent computing technique for fluid flow problems using hybrid adaptive neural network and genetic algorithm</article-title>. <source>Appl Soft Comput</source> <year>2011</year>; <volume>11</volume>(<issue>4</issue>): <fpage>3283</fpage>–<lpage>3296</lpage>.</citation></ref>
<ref id="bibr16-0954408912459161"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Massimiliano</surname><given-names>V</given-names></name><name><surname>Rushi</surname><given-names>B</given-names></name><name><surname>Oliver</surname><given-names>H</given-names></name><etal/></person-group>. <article-title>Predicting the exchange traded fund DIA with a combination of genetic algorithms and neural networks</article-title>. <source>Expert Syst Appl</source> <year>2004</year>; <volume>27</volume>(<issue>3</issue>): <fpage>417</fpage>–<lpage>425</lpage>.</citation></ref>
<ref id="bibr17-0954408912459161"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marghny</surname><given-names>HM</given-names></name></person-group>. <article-title>Rules extraction from constructively trained neural networks based on genetic algorithms</article-title>. <source>Neurocomputing</source> <year>2011</year>; <volume>74</volume>(<issue>17</issue>): <fpage>3180</fpage>–<lpage>3192</lpage>.</citation></ref>
<ref id="bibr18-0954408912459161"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Saravanan</surname><given-names>N</given-names></name><name><surname>Cholairajan</surname><given-names>S</given-names></name><name><surname>Ramachandran</surname><given-names>KI</given-names></name></person-group>. <article-title>Vibration-based fault diagnosis of spur bevel gear box using fuzzy technique</article-title>. <source>Expert Syst Appl</source> <year>2009</year>; <volume>36</volume>(<issue>2</issue>): <fpage>3119</fpage>–<lpage>3135</lpage>.</citation></ref>
<ref id="bibr19-0954408912459161"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Demetgul</surname><given-names>M</given-names></name><name><surname>Tansel</surname><given-names>IN</given-names></name><name><surname>Taskinc</surname><given-names>S</given-names></name></person-group>. <article-title>Fault diagnosis of pneumatic systems with artificial neural network algorithms</article-title>. <source>Expert Syst Appl</source> <year>2009</year>; <volume>36</volume>(<issue>7</issue>): <fpage>10512</fpage>–<lpage>10519</lpage>.</citation></ref>
<ref id="bibr20-0954408912459161"><label>20</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gemmell</surname><given-names>BD</given-names></name><name><surname>McDonald</surname><given-names>JR</given-names></name><name><surname>Stewart</surname><given-names>RW</given-names></name><etal/></person-group>. <article-title>Consultative expert system for fault diagnosis of turbine-generator plant</article-title>. <source>Proc IMechE Part A: J Power Energy</source> <year>1994</year>; <volume>208</volume>(<issue>4</issue>): <fpage>257</fpage>–<lpage>266</lpage>.</citation></ref>
<ref id="bibr21-0954408912459161"><label>21</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>XM</given-names></name><name><surname>Hu</surname><given-names>QH</given-names></name><name><surname>Lei</surname><given-names>YG</given-names></name><etal/></person-group>. <article-title>Vibration-based fault diagnosis of slurry pump impellers using neighbourhood rough set models</article-title>. <source>Proc IMechE Part C: J Mech Eng Sci</source> <year>2010</year>; <volume>224</volume>(<issue>4</issue>): <fpage>995</fpage>–<lpage>1006</lpage>.</citation></ref>
<ref id="bibr22-0954408912459161"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Xiong</surname><given-names>G</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><etal/></person-group>. <article-title>Fault diagnosis based on optimized node entropy using lifting wavelet packet transform and genetic algorithms</article-title>. <source>Proc IMechE Part I: J Syst Control Eng</source> <year>2010</year>; <volume>224</volume>(<issue>5</issue>): <fpage>557</fpage>–<lpage>573</lpage>.</citation></ref>
<ref id="bibr23-0954408912459161"><label>23</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>ZQ</given-names></name><name><surname>Zhu</surname><given-names>QX</given-names></name></person-group>. <article-title>Rough set-based heuristic hybrid recognizer and its application in fault diagnosis</article-title>. <source>Expert Syst Appl</source> <year>2009</year>; <volume>36</volume>(<issue>2</issue>): <fpage>2711</fpage>–<lpage>2718</lpage>.</citation></ref>
</ref-list>
</back>
</article>