<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v2.3 20070202//EN" "journalpublishing.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">NCP</journal-id>
<journal-id journal-id-type="hwp">spncp</journal-id>
<journal-id journal-id-type="nlm-ta">Nutr Clin Pract</journal-id>
<journal-title>Nutrition in Clinical Practice</journal-title>
<issn pub-type="ppub">0884-5336</issn>
<issn pub-type="epub">1941-2452</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1177/0884533613478636</article-id>
<article-id pub-id-type="publisher-id">10.1177_0884533613478636</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Invited Reviews</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Basic Statistical Concepts in Nutrition Research</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name><surname>Saracino</surname><given-names>Giovanna</given-names></name>
<degrees>MS</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Jennings</surname><given-names>Linda W.</given-names></name>
<degrees>PhD</degrees>
</contrib>
<contrib contrib-type="author">
<name><surname>Hasse</surname><given-names>Jeanette M.</given-names></name>
<degrees>PhD, RD, LD, FADA, CNSC</degrees>
</contrib>
<aff id="aff1-0884533613478636">Annette C. and Harold C. Simmons Transplant Institute at Baylor University Medical Center, Dallas, Texas</aff>
</contrib-group>
<author-notes>
<corresp id="corresp1-0884533613478636">Giovanna Saracino, MS, Annette C. and Harold C. Simmons Transplant Institute, Baylor University Medical Center, 3410 Worth St, Suite 950, Dallas, TX 75246, USA. Email: <email>giovanns@baylorhealth.edu</email>.</corresp>
</author-notes>
<pub-date pub-type="epub-ppub">
<month>4</month>
<year>2013</year>
</pub-date>
<volume>28</volume>
<issue>2</issue>
<issue-title>Research and Publishing</issue-title>
<fpage>182</fpage>
<lpage>193</lpage>
<history>
<date date-type="received">
<day>8</day>
<month>1</month>
<year>2013</year>
</date>
<date date-type="accepted">
<day>21</day>
<month>1</month>
<year>2013</year>
</date>
</history>
<permissions>
<copyright-statement>© 2013 American Society for Parenteral and Enteral Nutrition</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder content-type="society">The American Society for Parenteral and Enteral Nutrition</copyright-holder>
</permissions>
<abstract>
<p>Statistical principles are used in nutrition research to plan and conduct research studies and to answer research questions. This article describes general statistical concepts and provides some guidelines to assist in the interpretation of research literature. Prospective and retrospective study designs used in nutrition research are presented as well as the advantages and disadvantages of each of the study designs. Descriptive statistics used to summarize data and graphical tools used to display the shape of the distribution of a set of data guide nutrition support professionals to select appropriate statistical tests. Fundamental topics of statistics, including power analysis and sample size, confidence intervals and hypothesis testing, and analysis of variance and regression, are also reviewed. The article emphasizes the importance of effective collaboration with statisticians at an early stage of the research study to avoid potential pitfalls associated with improper utilization of statistical methods.</p>
</abstract>
<kwd-group>
<kwd>research design</kwd>
<kwd>statistics</kwd>
<kwd>biostatistics</kwd>
<kwd>sample size</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Nutrition is a quantitative but not an exact science. Humans have different biological mechanisms that can affect their metabolism and response to dietary patterns or nutrition interventions. To account for this, statistics is used in research to handle and quantify variation and uncertainty. Through the application of the scientific research methodology, nutrition science acquires new knowledge and tests new ideas. Statistics provides empirical evidence and a language for communicating scientific results. This article provides some guidance interpreting and understanding basic statistics used in nutrition research literature.</p>
<sec id="section1-0884533613478636">
<title>Study Design</title>
<p>Once a nutrition investigator has formulated a research question, the next step will be how to answer the question. This is done by the selection of an appropriate study methodology, which will guide nutrition investigators on how to collect, analyze, and interpret data. This ensures that the research is valid and adequately designed.</p>
<p>An investigator may take an observational or an experimental approach to carry out a nutrition research study. The characteristics of the study, the research questions being addressed, and the resources available influence the design choice. A basic understanding of study design can enable the reader of research papers to evaluate whether the study methodology used by the authors is valid and what is appropriate to infer from the study results. <xref ref-type="table" rid="table1-0884533613478636">Table 1</xref> provides an overview of the most common study designs used in nutrition research and summarizes strengths and limitations of each.<sup><xref ref-type="bibr" rid="bibr1-0884533613478636">1</xref>,<xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref></sup></p>
<table-wrap id="table1-0884533613478636" position="float">
<label>Table 1.</label>
<caption>
<p>Research Study Designs: Advantages and Disadvantages.</p>
</caption>
<graphic alternate-form-of="table1-0884533613478636" xlink:href="10.1177_0884533613478636-table1.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">Study Type</th>
<th align="center">Time Perspective</th>
<th align="center">Study Design</th>
<th align="center">Description</th>
<th align="center">Advantages</th>
<th align="center">Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td>Experimental</td>
<td>Prospective</td>
<td>Controlled clinical trials</td>
<td>Subjects are allocated in the interventional or control group based on study design and randomization mechanisms.</td>
<td>Researchers can control for sources of bias and variability through randomization and blinding.</td>
<td>This is an expensive study design.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Study design can protect against confounders.</td>
<td>This type of study is not always feasible.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>This study type provides strongest evidence for cause-and-effect association.</td>
<td>There is risk to subjects.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td/>
<td>Study design can have ethical implications.</td>
</tr>
<tr>
<td>Observational</td>
<td>Prospective</td>
<td>Current-cohort</td>
<td>Subjects are selected for observation at study initiation and followed over time. Outcome is observed and recorded throughout the study.</td>
<td>There is no human intervention in assigning study groups.</td>
<td>There is no randomization or any type of subject allocation.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>There is no risk to subjects.</td>
<td>There is no control for confounding variables.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Study design is suited to study risk factors and to estimate incidence and relative risk.</td>
<td>Lengthy duration of follow-up is required.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Subjects are followed over time so researchers can assess association.</td>
<td>Validity of study is affected if large numbers of subjects are lost to follow-up.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Researchers can look at several outcomes simultaneously.</td>
<td>Large numbers of subjects are required to study rare outcomes.</td>
</tr>
<tr>
<td>Observational</td>
<td>Retrospective</td>
<td>Cross-sectional</td>
<td>Information on outcomes of interest and variables affecting outcomes are provided at a given time point.</td>
<td>Design is suited to study the prevalence of a health outcome.</td>
<td>It is difficult to distinguish association from causation in this type of study.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>This design is quick and inexpensive.</td>
<td>This type of study is not efficient to study rare outcomes.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>No follow-up of subjects is required.</td>
<td/>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>There is no risk to subjects.</td>
<td/>
</tr>
<tr>
<td>Observational</td>
<td>Retrospective</td>
<td>Case-control</td>
<td>Subjects are selected based on a certain condition under study and are compared with subjects in whom the condition is not present.</td>
<td>Design is suited to study rare outcomes.</td>
<td>Controls can be incomplete and difficult to define.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Design is suited to study the influence of predictors on outcome and to estimate odd ratios.</td>
<td>This type of study is prone to selection and recall bias.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Researchers can only look at one outcome.</td>
<td/>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>This design is quick and inexpensive.</td>
<td/>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>There is no risk to subjects.</td>
<td/>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>This type of study is useful for hypothesis generation.</td>
<td/>
</tr>
<tr>
<td>Observational</td>
<td>Retrospective</td>
<td>Historical-cohort</td>
<td>Outcomes have already occurred before the start of investigation. The cohort is followed retrospectively.</td>
<td>There is no human intervention in assigning study groups.</td>
<td>No randomization or any type of subject allocation is used.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>There is no risk to subjects.</td>
<td>There is no control for confounding variables.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Design is suited to study risk factors and to estimate incidence and relative risk.</td>
<td>Lengthy duration of follow-up is required.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Subjects are followed over time to assess association.</td>
<td>Validity of study is affected if large numbers of subjects are lost to follow-up.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Researchers can look at several outcomes simultaneously.</td>
<td>Large numbers of subjects are required to study rare outcomes.</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td/>
<td>This type of study is prone to recall bias.</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>The randomized controlled clinical trial is universally considered the “gold standard” to answer a research question.<sup><xref ref-type="bibr" rid="bibr3-0884533613478636">3</xref></sup> It allows the investigator to identify and control, as much as possible, for known sources of variation. It also provides methods for removing the effect of confounding variables, those that can affect the outcome but are not under investigation. The process of randomization controls for bias.<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref></sup> The drawback of randomized controlled experimental studies is that they may not be feasible, they may be too expensive, and the duration for subject recruitment and follow-up analysis may be very long. In addition, ethical considerations may also restrict human experimentation. Therefore, often the choices for the investigator are limited to observational studies that can be prospective or retrospective.<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref></sup></p>
<sec id="section2-0884533613478636">
<title>Prospective Studies</title>
<p>Prospective studies proceed from a postulated cause of an outcome to an effect. As already mentioned, the randomized controlled clinical trial is the only prospective interventional trial. The prospective observational study design is called a cohort study.<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref><xref ref-type="bibr" rid="bibr3-0884533613478636"/>-<xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> An example of a prospective cohort study would be one in which a cohort of infants is prospectively followed for a number of years to identify risk factors for obesity in childhood. Early growth is observed along with factors suspected to influence the development of obesity.</p>
</sec>
<sec id="section3-0884533613478636">
<title>Retrospective Studies</title>
<p>Retrospective studies use information from past events and proceed from an observed effect to the cause. Cross-sectional, case-control, and historical cohort studies are examples of retrospective studies.<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref></sup> A study that looks at the prevalence of in-hospital surgical wound infection in obese and nonobese patients at a certain point in time is an example of cross-sectional study. Survival and complications of nursing home residents with dementia being tube fed compared with a matched control of similar residents who are hand fed is an example of case-control study. An example of a historical cohort study is one in which the length of stay of ventilated trauma patients in an intensive care unit receiving tube feeding by 2 different enteral feeding protocols is retrospectively analyzed.</p>
</sec></sec>
<sec id="section4-0884533613478636">
<title>Data Collection</title>
<p>Before being analyzed, data must be collected, reviewed, coded, verified, and prepared in a format suitable for the analysis. At this step, the investigator needs to specify and define the study end points, potential predictors, and confounding factors that need to be collected and how they will be measured.<sup><xref ref-type="bibr" rid="bibr1-0884533613478636">1</xref></sup> In retrospective studies, the investigator will assess if the variables of interest are already captured in existing databases and if supplementary data collection and retrospective chart review may be required. The investigator will conduct a feasibility study to investigate the availability of information, the best means of data collection, and the cost and resources needed to carry out the study. The researcher will also assess if additional follow-up data need to be collected based on the research question and the study design. Collaboration with a statistician will ensure that all data needed to answer the research questions are collected and properly prepared for the statistical analysis.<sup><xref ref-type="bibr" rid="bibr3-0884533613478636">3</xref></sup></p>
</sec>
<sec id="section5-0884533613478636">
<title>Characteristics of Data</title>
<p>Authors of research papers use different methods to summarize, analyze, and present data. The choice of the statistical method used is related to the type of data and its distributional shape. Data can be categorical or quantitative. Quantitative data can be continuous or discrete.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref>,<xref ref-type="bibr" rid="bibr6-0884533613478636">6</xref></sup></p>
<sec id="section6-0884533613478636">
<title>Categorical Data</title>
<p>Categorical data result from grouping a set of data into categories, based on a certain attribute. If data can be ranked or arranged on some inherent ordering, then categorical data are said to be ordinal. For example, in nutrition studies conducted in blood and marrow transplant patients with acute graft vs host disease (GVHD), the overall grading (staged from a low of I to a high of IV) is assessed to determine the severity of the disease. Overall grading of acute GVHD is an example of a categorical and, more specifically, ordinal variable since the higher the overall grade of acute GVHD, the worse the overall outcome. Categorical data that cannot be ordered but can only be assigned a name or a label, such as race and sex, are said to be nominal. Bar charts and pie charts are used to graph categorical data.</p>
</sec>
<sec id="section7-0884533613478636">
<title>Quantitative Data</title>
<p>Quantitative data are those that can be measured or counted; they can be continuous or discrete.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref></sup> Continuous data result from measuring something. They are numerical variables, and their measurements are expressed in units. Weight, expressed in kilograms, is an example of continuous data. Continuous data can be used in their original form of numeric variables or can be categorized based on cutoffs, quartiles, or standard definitions. For example, body mass index (BMI) can be analyzed as a continuous variable or converted into specific categories such as underweight, normal weight, overweight, and obese and treated as categorical data.</p>
<p>Discrete data arise from counting, and they usually consist of whole numbers (or integers). For example, the number of meals per day a patient eats and the number of intermittent feedings administered to a patient per day via a feeding tube are examples of discrete data.</p>
</sec>
<sec id="section8-0884533613478636">
<title>Distribution of Quantitative Data</title>
<p>Whether quantitative data are discrete or continuous, how the data are distributed and the shape of the distribution help determine the appropriate statistical methods for the analysis. Statistical tests that rely on assumptions about the underlying distribution are referred to as parametric tests. To determine if a parametric test is appropriate to evaluate the data, one must look at the shape or distribution of the data.<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref><xref ref-type="bibr" rid="bibr3-0884533613478636"/><xref ref-type="bibr" rid="bibr4-0884533613478636"/><xref ref-type="bibr" rid="bibr5-0884533613478636"/><xref ref-type="bibr" rid="bibr6-0884533613478636"/>-<xref ref-type="bibr" rid="bibr7-0884533613478636">7</xref></sup> The normal distribution, a symmetric bell-shaped distribution such as the one for weights depicted in <xref ref-type="fig" rid="fig1-0884533613478636">Figure 1</xref>, is the most popular type of distribution that is appropriate for analysis by a parametric test.</p>
<fig id="fig1-0884533613478636" position="float">
<label>Figure 1.</label>
<caption>
<p>Grouped frequency histogram with normal curve overlay generated from a random sample of weights in kilograms of 900 liver transplant patients. The data were broken down into 13 equal class intervals. The smooth line was generated as a symmetrical bell-shaped curve overlying the histogram representing a normal population distribution.</p>
</caption>
<graphic xlink:href="10.1177_0884533613478636-fig1.tif"/></fig>
<p>An empirical way to discover the shape of the distribution of a set of data could be to graphically display them using a histogram with a normal curve overlay as in <xref ref-type="fig" rid="fig1-0884533613478636">Figure 1</xref> or a boxplot as in <xref ref-type="fig" rid="fig2-0884533613478636">Figure 2</xref>. Boxplots are very informative graphs that summarize location, spread, and shape of data of a quantitative variable and aid in determining potential outliers. The upper and lower ends of the box indicate the 25th and 75th percentiles (or the lower and upper quartiles). The line inside the box indicates the median, or the 50th percentile, and the length of the box is the interquartile range. The mean is usually indicated with a symbol. The larger the interquartile range or the size of the box, the more spread out the data are. If the distribution is symmetric, the line that indicates the median is close to the center of the box, and the mean and the median are very close.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref></sup> If most of the data values are concentrated below or above the median value, then the distribution is skewed. The central vertical lines are called whiskers, and they extend up to 1.5 the interquartile range. Values outside the whiskers are called outliers. Outliers are values unexpectedly different from other values. The identification of potential outliers is important. Outliers can be the result of data errors, and if so, they can heavily affect the analysis if not removed or corrected. Outliers can also be legitimate values, might have some meaning, and shed some light on important issues. They can inspire further investigation. Sometimes outliers are left in and sometimes are taken out. Before removing these extreme points from the data, researchers should understand why they appeared and whether similar values will continue to appear because they are part of the inherent variability of the data. Moreover, side-by-side boxplots (<xref ref-type="fig" rid="fig3-0884533613478636">Figure 3</xref>) illustrate location and variation changes between groups.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref><xref ref-type="bibr" rid="bibr6-0884533613478636"/><xref ref-type="bibr" rid="bibr7-0884533613478636"/>-<xref ref-type="bibr" rid="bibr8-0884533613478636">8</xref></sup></p>
<fig id="fig2-0884533613478636" position="float">
<label>Figure 2.</label>
<caption>
<p>The boxplot graph provides a very informative summary of the location, spread, and shape of the data. It depicts the mean, the median, the first and third percentiles, and the whiskers. Values outside the whiskers are called outliers.</p>
</caption>
<graphic xlink:href="10.1177_0884533613478636-fig2.tif"/></fig>
<fig id="fig3-0884533613478636" position="float">
<label>Figure 3.</label>
<caption>
<p>Example of a side-by-side boxplot, which can be used to compare results from 2 groups.</p>
</caption>
<graphic xlink:href="10.1177_0884533613478636-fig3.tif"/></fig>
<p>In addition to graphical displays, the distribution of data can be described with summary measures of the location, spread, and shape. The choice of appropriate measures of location and spread depends on the type of variable and the shape of the distribution. The location represents the center of the distribution. The mean and the median are 2 widely used measures of location with nutrition data. The mean better describes the center of a symmetric distribution. The median, more robust and less affected by extreme values, is more suitable than the mean to describe the center of a skewed distribution or to summarize ordinal data, regardless of the shape of the distribution.<sup><xref ref-type="bibr" rid="bibr8-0884533613478636">8</xref></sup> The spread represents how much data are dispersed around the mean or the median. Most common summary statistics that measure the spread in the data values are the standard deviation, the interquartile range, and the range. The standard deviation measures the spread around the mean and, like the mean, is sensitive to outliers. If data are normally distributed or approximately normal, then that means that generally, 95% of the values lie within 2 standard deviations from the mean and 99% of the values within 3 standard deviations from the mean. If the data are skewed or ordinal, the interquartile range and the range are appropriate measures of spread, and they are always reported with the median. The interquartile range is less affected by outliers than the range.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref></sup></p>
<p>In most nutrition research manuscripts, there is an initial table that describes the characteristics of the subjects in the study. Summary statistics of location and spread are often provided, and categorical variables are described through frequency distributions.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref></sup> The reader of nutrition research papers should be familiar with types of data and their distributions and understand when they are described with measures of location and spread that are not appropriate. Authors will not always explicitly mention the data type and distribution shape. When they do, most of this information is usually summarized in the methods section of a manuscript.</p>
<p>To sum up, before data are analyzed, investigators should perform an appropriate exploratory data analysis. A preliminary look at the data will help investigators become familiar with the data, detect data errors, learn about variable distributions and relationship between variables, and check for the assumptions before applying a statistical methodology.</p>
</sec></sec>
<sec id="section9-0884533613478636">
<title>Incidence vs Prevalence</title>
<p>In nutrition epidemiology, researchers often present their findings in terms of incidence and prevalence, which measure 2 different aspects of a condition.</p>
<sec id="section10-0884533613478636">
<title>Incidence</title>
<p>The incidence is the rate of new cases that arise during a specified time period in a defined population.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> The denominator is the number of individuals exposed to the risk and the numerator is the number of individuals who experience the condition during a predefined time period. Incidence is a measure of risk, or the chance that an exposed individual experiences the event. Prospective cohort studies are designed to estimate incidence. For example, a population of infants born to obese mothers are followed for a certain period to see how many of them become obese.<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref><xref ref-type="bibr" rid="bibr3-0884533613478636"/>-<xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup></p>
</sec>
<sec id="section11-0884533613478636">
<title>Prevalence</title>
<p>Prevalence refers to the proportion of individuals in a defined population, who have a specific condition (both new and existing cases) observed at a specific point in time.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> Retrospective cross-sectional studies are suited to estimate prevalence that measures the magnitude of presence of a condition. For example, we count the number of children younger than 10 years in a specified geographic area at a point of time and we find that 30% of these children are obese. Prevalence measures the magnitude of childhood obesity; it does not measure the speed of its occurrence. It is like a snapshot of the problem of childhood obesity in a certain point in time.</p>
</sec></sec>
<sec id="section12-0884533613478636">
<title>Relative Risk vs Odds Ratio</title>
<p>When researchers want to compare exposures to a risk with another group, a control group, they use relative risk (RR) and the odds ratio (OR).<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup></p>
<sec id="section13-0884533613478636">
<title>Relative Risk</title>
<p>The RR is the ratio of 2 incidence rates. The ratio of risk of obesity for children born to obese mothers vs that of children born to normal-weight mothers is an example of RR. A RR of 2.0 can be interpreted that children with obese mothers are twice as likely to become obese as are children with normal-weight mothers, providing that all other factors are the same. If RR is equal to 1, it means that the 2 groups have same risk.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> To estimate RR, prospective cohort studies are required to calculate incidence rates, but they can be expensive and difficult to conduct.</p>
</sec>
<sec id="section14-0884533613478636">
<title>Odds Ratio</title>
<p>Case-control studies can be easier to perform and less expensive than cohort studies. Case-control studies can be used to determine the OR, which is defined as the ratio of 2 prevalence rates. For example, cases of obese children and matched controls of nonobese children can be retrospectively reviewed to determine if the children were born to obese or normal-weight mothers. This type of design is suited to calculate the prevalence of obesity in cases (children to obese mothers) and in the controls (children to normal-weight mothers).<sup><xref ref-type="bibr" rid="bibr2-0884533613478636">2</xref><xref ref-type="bibr" rid="bibr3-0884533613478636"/>-<xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> OR equal to 1 indicates that the mother’s weight does not change the odds on childhood obesity. When the prevalence of a condition is low, the OR is approximately the same as RR. In this case, the RR can be estimated from a retrospective study that is easier and less expensive to conduct than prospective studies.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup></p>
</sec></sec>
<sec id="section15-0884533613478636">
<title>Sample Size and Hypothesis Testing</title>
<p>A research question, often expressed in the form of the belief that some effect exists in a population, can be answered with hypothesis testing.<sup><xref ref-type="bibr" rid="bibr6-0884533613478636">6</xref></sup> The null hypothesis (H<sub>0</sub>) is a statement about the population, which is assumed to be true. The alternative hypothesis (H<sub>a</sub>) is a statement that contradicts the null hypothesis, H<sub>0</sub>.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> For example, a researcher wants to determine if obese children enrolled in an experimental healthy eating plan will lose the same amount of weight as children in a traditional meal plan. The null hypothesis could be expressed through the statement that obese children enrolled in an experimental meal plan for 6 months do not lose more weight than children in a traditional meal plan. The alternative hypothesis could state that obese children enrolled for 6 months in an experimental healthy food plan lose more weight than those in a traditional meal plan.</p>
<p>Before hypothesis testing, researchers determine the level of significance α, often chosen equal to 0.05 or 0.01,<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> which is the criterion used to reject the null hypothesis and determine statistical significance. More specifically, a representative sample of the population is analyzed for evidence against the null hypothesis, by computing a test statistic and a <italic>P</italic> value. The <italic>P</italic> value is the probability of obtaining a sample test statistic as extreme or more extreme than the one observed, given that the null hypothesis is true.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> As the outcome gets more unlikely, the <italic>P</italic> value gets smaller. If the <italic>P</italic> value is smaller than α, there is enough evidence to reject the null hypothesis.</p>
<p>By selecting the level of significance, the researcher controls the probability of incorrectly rejecting the null hypothesis. That is why researchers state what they want to prove in the alternative hypothesis. There are many statistical tests seen in nutrition research papers. They are influenced by type of data and shape of the distribution.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref></sup> In addition, when groups are compared, researchers need to know if groups are independent or correlated with each other.</p>
<p>For categorical data, χ<sup>2</sup> is used as a test for statistical significance.<sup><xref ref-type="bibr" rid="bibr9-0884533613478636">9</xref></sup> For example, we hypothesize that there is a relationship between the type of diet followed and the success of dieters in losing 10% of initial body weight. The <italic>t</italic> tests are used with continuous data to compare the averages of 2 groups.<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref><xref ref-type="bibr" rid="bibr6-0884533613478636"/>-<xref ref-type="bibr" rid="bibr7-0884533613478636">7</xref></sup> For example, they can compare mean BMI in the 2 unpaired groups, male and female, and determine whether a significant difference existed between the 2 groups.</p>
<p>In hypothesis testing, because the decision to reject or not to reject a null hypothesis is based on sample evidence, there is always the possibility to make the wrong decision. <xref ref-type="table" rid="table2-0884533613478636">Table 2</xref> describes 4 alternative decisions regarding the null hypothesis. The null hypothesis is either true or false. If the null hypothesis is not rejected when it is true or, conversely, is rejected when it is false, no error will have been made. A type I error is made when there is no effect in the population and the null hypothesis is rejected, whereas a type II error is made if there is an effect in the population but the null hypothesis is not rejected (<xref ref-type="table" rid="table2-0884533613478636">Table 2</xref>). Hypothesis testing is intended to control the risk of false claims. Thus, α is set to as low a value as possible to guard against type I error. A type II error, or false negative, mainly occurs when studies are small or variability of data is large. The power of a test is its ability to detect a true effect if such effect exists and is indicated with (1 – β). The power of a test and sample size are related. For example, suppose we want to test the hypothesis that men on average weigh more than women and we take a sample of 3 men and 3 women. We might find 3 overweight women and 3 underweight men by chance and conclude wrongly that men on average weigh less than women. If we take an unbiased sample of 100 women and 100 men, we are less likely to make a similar mistake. If the sample size is too small, it will be difficult to detect an important effect. Therefore, underpowered studies may not yield any useful results. The power of a study is also related to the type II error. As the power increases, the probability of a type II error, or the likelihood to conclude that there is not an effect in the population when in reality there is one, decreases.<sup><xref ref-type="bibr" rid="bibr10-0884533613478636">10</xref></sup></p>
<table-wrap id="table2-0884533613478636" position="float">
<label>Table 2.</label>
<caption>
<p>Possible Outcomes of Hypothesis Testing.</p>
</caption>
<graphic alternate-form-of="table2-0884533613478636" xlink:href="10.1177_0884533613478636-table2.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="left"/>
<col align="left"/>
<col align="left"/>
</colgroup>
<thead>
<tr>
<th/>
<th align="center" colspan="3">Decision Based on Statistical Results<hr/></th>
</tr>
<tr>
<th align="center">Truth in the Population</th>
<th align="center">Decision</th>
<th align="center">Error</th>
<th align="center">Probability</th>
</tr>
</thead>
<tbody>
<tr>
<td>H<sub>0</sub> is true</td>
<td>Reject H<sub>0</sub></td>
<td>Type I</td>
<td>α = probability (type I error)</td>
</tr>
<tr>
<td/>
<td>Fail to reject H<sub>0</sub></td>
<td>Correct decision</td>
<td>1 – α</td>
</tr>
<tr>
<td>H<sub>0</sub> is false</td>
<td>Reject H<sub>0</sub></td>
<td>Correct decision</td>
<td>1 – β = power</td>
</tr>
<tr>
<td/>
<td>Fail to reject H<sub>0</sub></td>
<td>Type II</td>
<td>β = probability (type II error)</td>
</tr>
</tbody>
</table>
</table-wrap>
<p>Many factors are involved in power analysis: the sample size, the effect size (how large a difference is considered clinically significant), the variability, and the predefined significance level α.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref><xref ref-type="bibr" rid="bibr5-0884533613478636"/><xref ref-type="bibr" rid="bibr6-0884533613478636"/><xref ref-type="bibr" rid="bibr7-0884533613478636"/>-<xref ref-type="bibr" rid="bibr8-0884533613478636">8</xref></sup> Researchers usually tend to reduce the type I error because with a low significance level α, they are confident that the results obtained are not due to chance alone. The researcher determines the effect size that represents the difference in the outcomes that would be considered clinically significant. But the expected variability of the outcomes often cannot be optimized or controlled by the experimenter. For a given effect size and outcome variability, the only way to increase the power without increasing the significance level α is to increase the sample size.<sup><xref ref-type="bibr" rid="bibr10-0884533613478636">10</xref></sup> Furthermore, budget and other constraints can affect the sample size and a researcher might not be able to select a desired sample size. In this case, a power analysis will indicate the likelihood that the sample available was large enough to avoid false-negative results.</p>
<p>Power analysis should be performed at the study planning stage and should be the result of collaboration between the researcher and the statistician. The statistician needs to know and the researcher needs to provide the main end point of interest and how it is measured, the clinical significant effect size that is meaningful to detect, and an estimated measure of the variability of the response variable. An estimation of the expected variability is usually done by completing a pilot study or it is extracted from previous studies measuring the same outcome. A significance level α is commonly predefined to be either 0.01 or 0.05. In a hypothetical scenario, a researcher wants to conduct a power analysis for a study in which a group of obese children will be enrolled in an experimental healthy weight loss eating plan and another group in a traditional meal plan. In addition, the researcher decides to consider a predefined significance level of 0.05 or 0.01 and has reasons to believe that a mean difference of 7 or 8 kg after 6 months from the enrollment in a food plan would represent a clinically meaningful effect size. Furthermore, from a pilot sample, the researcher estimates a standard deviation of 19 kg, and for budget constraints, the sample size of obese children is planned to be of 200–300 subjects. <xref ref-type="fig" rid="fig4-0884533613478636">Figure 4</xref> illustrates the information the researcher provided and the combination of plausible factors influencing the power of the study. The power ranges from 0.74–0.85. With a confidence level of 0.05, a sample size of 200 subjects will be likely to detect an effect size, expressed as the mean weight difference in the 2 groups, of 7 kg with a power of 0.74. On the other hand, with a confidence level of 0.01, a sample size of 300 subjects will be likely to detect an effect size of 8 kg with a power of 0.85. Between these 2 extreme results, researchers can identify other intermediary scenarios and select an appropriate sample size.</p>
<fig id="fig4-0884533613478636" position="float">
<label>Figure 4.</label>
<caption>
<p>Plot of power vs sample size for a predefined significance level of 0.05 or 0.01 to detect a clinically meaningful difference of 7 or 8 kg.</p>
</caption>
<graphic xlink:href="10.1177_0884533613478636-fig4.tif"/></fig>
<p>If negative results are reported in a research paper, a reader should carefully evaluate if a power analysis was performed to determine the extent to which the proposed sample size is able to detect the hypothesized effect.</p>
</sec>
<sec id="section16-0884533613478636">
<title>Sample Size and Confidence Intervals</title>
<p>Confidence intervals (CIs) and hypothesis testing are often used to answer the same questions but in a different way. A sample statistic, calculated from a representative sample of the population, is the point estimate (or single best estimate) of a population parameter. As in hypothesis testing, the sample statistic used depends on the type and distribution of data.<sup><xref ref-type="bibr" rid="bibr10-0884533613478636">10</xref></sup> Therefore, a researcher can calculate a sample mean or a sample proportion as a point estimate of the mean and proportion in the population. Moreover, differences of sample means for independent and paired groups are sample estimates of differences in the means in the population. Because different samples can produce different estimates of population parameters, the sampling error measures and quantifies this variation that exists among estimates from different samples. A CI is a range of values that is likely to contain the true parameter of the population. The CI range is calculated by adding and subtracting from the point estimate a margin of error. The larger the sample size, the smaller the margin of error, the narrower the CI range, and the more precise the estimate.<sup><xref ref-type="bibr" rid="bibr11-0884533613478636">11</xref></sup> Confidence levels of 90%, 95%, or 99% are commonly chosen. The confidence level is related to the level of significance α in hypothesis testing and is expressed as 100(1 – α)%. Therefore, if a researcher selects a significance level of α = 0.05 in hypothesis testing, it corresponds to a 95% CI. This means that if 100 samples of the same size are selected, 95 of them would include the true parameter of the population mean µ, and 5 would not. <xref ref-type="fig" rid="fig5-0884533613478636">Figure 5</xref> depicts this concept. Furthermore, the confidence level is related to the precision: the higher the level of confidence, the wider the CI; conversely, the lower the level of confidence, the lower the precision.</p>
<fig id="fig5-0884533613478636" position="float">
<label>Figure 5.</label>
<caption>
<p>The graph shows confidence intervals of the population mean µ estimated from repeated samples of the same size. Most of them, with the exception of 2, contain µ.</p>
</caption>
<graphic xlink:href="10.1177_0884533613478636-fig5.tif"/></fig>
<p>A researcher wants to know if the average body weight is different for women in 2 different geographic locations. This question can be addressed by calculating a CI of the differences in the mean and see if it will contain 0 or can be answered testing the hypothesis that the mean difference is 0 and observing if the calculated <italic>P</italic> value is less than the predefined significance level. If the 95% CI includes 0, the <italic>P</italic> value will be .05 or greater, whereas if it does not contain 0, the <italic>P</italic> value will be &lt;.05 and there will be enough evidence to conclude that the average body weight of women in the 2 geographic locations is significantly different. CIs are preferred to hypothesis tests because they provide a range of possible values for the size of a difference, whereas hypothesis tests only indicate whether a difference is significant.</p>
</sec>
<sec id="section17-0884533613478636">
<title>Association</title>
<p>When statistical tests compare more than 2 groups, researchers are often interested in looking at how 2 or more variables appear to move together or how they are associated<sup><xref ref-type="bibr" rid="bibr5-0884533613478636">5</xref></sup>—for example, a researcher may want to know how weight is associated with height. The strength of an association depends on how close the points are to an imaginary straight line. <xref ref-type="fig" rid="fig6-0884533613478636">Figure 6</xref> illustrates a scatterplot of weight vs height with a straight line of best fit. The plot shows that there exists a kind of relationship between height and weight. The points seem to go upwards, from left to right, and the fitted line indicates the direction of this relationship. In nutrition research manuscripts, authors usually measure the strength of an association, or how close the points are to a straight line, using either the Pearson correlation coefficient or the Spearman correlation coefficient. Correlation coefficients vary between −1, which indicates a perfect negative association, and 1, or a perfect positive association. The closer to 1 or −1, the stronger the association, and the sign indicates the direction of the correlation. The decision to use the Pearson or Spearman correlation depends on data type and distributional shape. Researchers should follow the rule to use the Pearson correlation for data that are approximately normally distributed and the Spearman correlation for data that are not.<sup><xref ref-type="bibr" rid="bibr7-0884533613478636">7</xref></sup> Correlation is not causation, which means that just because 2 variables change together does not mean that one is causing the other. A positive correlation between BMI and blood pressure indicates that the greater the BMI, the greater the likelihood of high blood pressure. However, association does not mean that it is necessary that obesity (or increased BMI) is the cause of high blood pressure. To assess causation, researchers need to consider multivariable methods such as regression.</p>
<fig id="fig6-0884533613478636" position="float">
<label>Figure 6.</label>
<caption>
<p>Relationship between heights and weights. A fitted regression line is shown in the figure.</p>
</caption>
<graphic xlink:href="10.1177_0884533613478636-fig6.tif"/></fig>
</sec>
<sec id="section18-0884533613478636">
<title>Multivariable Methods</title>
<p>Regression analysis describes the relationship between a dependent variable, also known as an outcome or a response variable, and one or more independent variables, also known as explanatory or predictor variables.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> A mathematical equation describes this relationship between predictors and response, with the addition of an error term, generated because estimates of regression coefficients are calculated from sample data. Each predictor will have an estimated regression coefficient. If the estimate is close to zero, the predictor associated is not so relevant, and its presence in the regression equation is not needed. Researchers usually assess the significance of regression coefficients by performing hypothesis testing or calculating confidence intervals. An important characteristic of regression analysis is that the effect that each predictor has on the outcome is controlled, or adjusted, for the effect of the other significant predictors and interactions. Therefore, the regression coefficient measures the change in the outcome for a unit change in the value of the associated predictor, after controlling for all other significant predictors and interactions. This method allows examining for the effect of potential confounding variables.<sup><xref ref-type="bibr" rid="bibr4-0884533613478636">4</xref></sup> Researchers use variable selection methods, or a combination of methods, to decide which predictors are deemed important to explain the outcome and that need to be in the model. The stepwise method is a frequently used variable selection procedure that sorts through all possible candidate predictors in the model and chooses the most significant predictor, then the second most significant predictor, then the third, and so on. As more predictor variables enter the model, some may be removed if they are no longer significant predictors. When reading a research paper, it is important to determine how the authors decided which predictors and interactions to consider in the final regression model. Linear regression models are based on underlying assumptions, and research should verify that they hold. They should verify that the relationship between predictors and outcome is linear, that the distribution of the error term (or residual term) approximates a normal distribution, and that residuals have the same variability. A set of scatterplots of residuals can help researchers examine the basic assumptions of linear regression. To measure how well the regression equation can predict values that are close to the true outcome variables, authors report the coefficient of determination, or <italic>R</italic><sup>2</sup>, that ranges from 0 to 1. Large value of <italic>R</italic><sup>2</sup> indicates a good fit, or a good ability of the model to explain the outcome variable.</p>
<p>Nutrition researchers often work with dichotomous outcomes. For example, BMI can be categorized as obese (BMI ≥30 kg/m2) and nonobese (BMI &lt;30 kg/m2). Logistic regression is used to predict a categorical outcome. A peculiarity of logistic regression is that its coefficients can be interpreted in terms of ORs for the predictors or risk factors that are significantly affecting the outcome.<sup><xref ref-type="bibr" rid="bibr12-0884533613478636">12</xref></sup> Usually, researchers report an OR and its CI.</p>
<p>The analysis of variance (ANOVA) and linear regression analysis are almost interchangeable but are formulated differently. ANOVA requires all predictors to be categorical, whereas regression analysis is more generic and allows continuous, dichotomous, and categorical predictors. Both ANOVA and regression analysis achieve the same purpose of predicting a continuous outcome. Although <italic>t</italic> tests are frequently used in nutrition research to compare means of 2 groups, ANOVA is often used to compare means of more than 2 groups.<sup><xref ref-type="bibr" rid="bibr7-0884533613478636">7</xref></sup> Researchers perform a 1-way ANOVA when only 1 variable is analyzed. For example, a 1-way ANOVA is used to test if there is a difference in average of child BMI across 3 different groups defined by maternal education (less than high school, high school, and more than high school). If a second variable is also analyzed (eg, breakfast skipping), then researchers perform a 2-way ANOVA. Alternatively, a linear regression with child BMI as the outcome and maternal education and breakfast skipping as predictors could achieve the same goal.</p>
<p>A peculiarity of ANOVA is the partition of the total variability in the sample values of the outcome (eg, the child BMI) into the between-group variability that can be explained by the predictors in the model (eg, by different maternal education levels) and the within-group variability that cannot be explained by the predictors in the model. The within-group variability can be attributed to other predictors not included in the model and to random error. When researchers perform an ANOVA analysis, they report the value of an overall <italic>F</italic> test and its <italic>P</italic> value to assess the significance. For example, when testing the null hypothesis that the means of child BMI of the 3 maternal education levels are the same, a calculated <italic>F</italic> test with a <italic>P</italic> value &lt;.05 suggests the 3 BMI means are not likely to be equal. However, the <italic>F</italic> test does not provide information about which mean is different. A researcher could perform a series of <italic>t</italic> tests to identify the means that are significantly different. The problem with this approach is that the significant levels can be inflated and misleading. Therefore, post hoc multiple comparison tests are required and are explained below.</p>
</sec>
<sec id="section19-0884533613478636">
<title>Post Hoc Multiple Comparisons</title>
<p>When a researcher performs multiple tests on the same data, he or she will eventually end up with statistically significant results that occur just by chance. Post hoc multiple comparison tests are used to identify differences between groups and to rule out statistically significant differences due to chance alone. The Bonferroni correction, one of the most widely used multiple comparison methods, is an adjustment made to the <italic>P</italic> value when several tests are performed to answer the same overall statistical question. It keeps the overall significance level at α, by lowering the significance level α to α/n, where n is the number of comparisons.<sup><xref ref-type="bibr" rid="bibr13-0884533613478636">13</xref></sup> For example, a researcher wants to compare the means of child BMI for 3 maternal education levels after a significant <italic>F</italic> test to find out which group is different. In this scenario of 3 hypothesis tests and a chosen confidence level α of 0.05, the researcher would only reject the null hypothesis if the <italic>P</italic> value is &lt;.017.</p>
</sec>
<sec id="section20-0884533613478636">
<title>Statistical Significance and Clinical Significance</title>
<p>The definition of statistical significance is straightforward. It indicates the probability that the observed effect happened by chance when there is no true effect in the population. If the calculated <italic>P</italic> value is smaller than the predefined significance level indicated in the study design, then the null hypothesis can be rejected. A statistically significant effect should not be equated to a clinically significant effect.<sup><xref ref-type="bibr" rid="bibr1-0884533613478636">1</xref><xref ref-type="bibr" rid="bibr2-0884533613478636"/><xref ref-type="bibr" rid="bibr3-0884533613478636"/><xref ref-type="bibr" rid="bibr4-0884533613478636"/><xref ref-type="bibr" rid="bibr5-0884533613478636"/>-<xref ref-type="bibr" rid="bibr6-0884533613478636">6</xref></sup> To be clinically significant, an effect requires a substantial change that is thought to have a clinical impact. Statistical significance is influenced by sample size. When the sample size is large enough, statistically significant changes can be observed with negligible changes in important outcomes that are not clinically significant. The threshold of clinical significance is obtained from expert opinions and depends on the nature of the effect and its impact on the patient.</p>
</sec>
<sec id="section21-0884533613478636">
<title>Choosing the Correct Statistical Test</title>
<p>Inferential statistical tests can be parametric or nonparametric, and both approaches have advantages and disadvantages. Parametric tests assume a specific distribution, for example, the normal distribution to compare means. Nonparametric tests should be used when data are not normally distributed.<sup><xref ref-type="bibr" rid="bibr14-0884533613478636">14</xref></sup> <xref ref-type="table" rid="table3-0884533613478636">Table 3</xref> summarizes common inferential statistics used in the nutrition profession and provides guidance to choose among them based on the type of data (continuous or categorical), the number of factors and levels evaluated, and how groups are compared (between subjects or within subjects).<sup><xref ref-type="bibr" rid="bibr15-0884533613478636">15</xref></sup></p>
<table-wrap id="table3-0884533613478636" position="float">
<label>Table 3.</label>
<caption>
<p>Summary of Inferential Statistical Tests.<sup><xref ref-type="bibr" rid="bibr15-0884533613478636">15</xref></sup></p>
</caption>
<graphic alternate-form-of="table3-0884533613478636" xlink:href="10.1177_0884533613478636-table3.tif"/>
<table>
<colgroup>
<col align="left"/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
<col align="char" char="."/>
</colgroup>
<thead>
<tr>
<th align="left">No. of Factors<sup><xref ref-type="table-fn" rid="table-fn2-0884533613478636">a</xref></sup></th>
<th align="center">No. of Levels Evaluated<sup><xref ref-type="table-fn" rid="table-fn3-0884533613478636">b</xref></sup></th>
<th align="center">Type of Data (Continuous or Categorical)</th>
<th align="center">Type of Data Distribution (Normal or Nonnormal)</th>
<th align="center">Type of Test (Between Subjects or Within Subjects)</th>
<th align="center">Statistical Test</th>
<th align="center">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
<td>Continuous</td>
<td>Normal</td>
<td>Between</td>
<td><italic>t</italic> test</td>
<td>Comparing body mass index (BMI) at start of therapy between patients receiving tube feeding and patients receiving parenteral nutrition (PN)</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Within</td>
<td>Paired <italic>t</italic> test</td>
<td>Comparing BMI prealbumin of patients at start and after 2 months of tube feeding</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>Continuous</td>
<td>Nonnormal</td>
<td>Between</td>
<td>Mann-Whitney</td>
<td>Comparing length of hospital stay between patients receiving tube feeding and patients receiving PN</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Within</td>
<td>Wilcoxon</td>
<td>Comparing a depression test score of patients after 1 week of continuous tube feeding and again after 1 week of cyclic tube feeding</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>Categorical</td>
<td>Nonnormal</td>
<td>Between</td>
<td>Chi square</td>
<td>Comparing presence of pressure sores vs absence of pressure sores between patients receiving tube feeding and patients receiving PN</td>
</tr>
<tr>
<td>1</td>
<td>3 or more</td>
<td>Continuous</td>
<td>Normal</td>
<td>Between</td>
<td>Analysis of variance (ANOVA)</td>
<td>Comparing BMI at start of therapy between patients receiving diet, patients receiving tube feeding, and patients receiving PN</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Within</td>
<td>Repeated-measures ANOVA</td>
<td>Comparing BMI of patients at start, after 2 months, and after 4 months of tube feeding</td>
</tr>
<tr>
<td>1</td>
<td>3 or more</td>
<td>Continuous</td>
<td>Nonnormal</td>
<td>Between</td>
<td>Kruskal-Wallis 1-way analysis for ranks</td>
<td>Comparing length of hospital stay between patients receiving diet, patients receiving tube feeding, and patients receiving PN</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Within</td>
<td>Friedman 2-way ANOVA</td>
<td>Comparing a depression test score of patients after 1 week of continuous tube feeding, after 1 week of cyclic tube feeding, and again after 1 week of intermittent tube feeding</td>
</tr>
<tr>
<td>1</td>
<td>3 or more</td>
<td>Categorical</td>
<td>Nonnormal</td>
<td>Between</td>
<td>Chi square</td>
<td>Comparing presence of pressure sores vs absence of sores between patients receiving diet, patients receiving tube feeding, and patients receiving PN</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Within</td>
<td>Cochran <italic>Q</italic></td>
<td>Comparing presence of abdominal distension in patients after 1 week of continuous tube feeding, after 1 week of cyclic tube feeding, and again after 1 week of intermittent tube feeding</td>
</tr>
<tr>
<td>2 or more</td>
<td>2 or more</td>
<td>Continuous</td>
<td>Normal</td>
<td>Between for all factors</td>
<td>Factorial ANOVA</td>
<td>Comparing BMI between patients receiving tube feeding with or without growth hormone and patients receiving PN with or without growth hormone</td>
</tr>
<tr>
<td/>
<td/>
<td/>
<td/>
<td>Within for at least 1 factor</td>
<td>Repeated-measures ANOVA</td>
<td>Comparing BMI of patients receiving tube feeding and patients receiving PN at start of therapy and again after 2 months of therapy</td>
</tr>
<tr>
<td>2 or more</td>
<td>2 or more</td>
<td>Continuous</td>
<td>Nonnormal</td>
<td colspan="3">Contact a statistician for special tests</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="table-fn1-0884533613478636"><p>©1998 Support Line, Dietitians in Nutrition Support, a dietetic practice group of the American Dietetic Association. Used with permission.</p></fn>
<fn id="table-fn2-0884533613478636">
<label>a</label>
<p>Factors: classifying variables or number of variables used to distinguish patient groups (eg, type of nutrition).</p></fn>
<fn id="table-fn3-0884533613478636">
<label>b</label>
<p>Levels: number of groups in each factor (eg, for the factor “type of nutrition,” 2 levels are tube feeding and PN).</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="section22-0884533613478636" sec-type="conclusions">
<title>Conclusion</title>
<p>Statistical analysis is an integral part of nutrition research. There are potential pitfalls associated with the application and interpretation of statistical methods. Many statistical resources are available on the Internet, and statistical software is widely available. They are relatively easy to use and misuse if users do not know how to interpret the results they produce and the assumptions under which their results are valid. This article outlines basic statistical concepts that can help nutrition support clinicians understand the statistical terminology used in nutrition research literature and assists researchers to appropriately use statistical software to produce valid results. Moreover, it encourages researchers to seek the help of a statistician at an early stage of their research studies to ensure that appropriate statistical methodology is used.</p>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="financial-disclosure">
<p>Financial disclosure: None declared.</p>
</fn>
<fn fn-type="other">
<p>This article originally appeared online on February 28, 2013.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-0884533613478636">
<label>1.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Bowers</surname><given-names>D</given-names></name>
<name><surname>House</surname><given-names>A</given-names></name>
<name><surname>Owens</surname><given-names>D</given-names></name>
</person-group>. <source>Understanding Clinical Papers</source>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>John Wiley</publisher-name>; <year>2000</year>.</citation>
</ref>
<ref id="bibr2-0884533613478636">
<label>2.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Chow</surname><given-names>SC</given-names></name>
<name><surname>Liu</surname><given-names>JP</given-names></name>
</person-group>. <source>Design and Analysis of Clinical Trials: Concept and Methodologies</source>. <publisher-loc>Chichester, UK</publisher-loc>: <publisher-name>John Wiley</publisher-name>; <year>1998</year>.</citation>
</ref>
<ref id="bibr3-0884533613478636">
<label>3.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boushey</surname><given-names>C</given-names></name>
<name><surname>Harris</surname><given-names>J</given-names></name>
<name><surname>Bruemmer</surname><given-names>B</given-names></name>
<name><surname>Archer</surname><given-names>SL</given-names></name>
<name><surname>Van Horn</surname><given-names>L</given-names></name>
</person-group>. <article-title>Publishing nutrition research: a review of study design, statistical analyses, and other key elements of manuscript preparation, part 1</article-title>. <source>J Am Diet Assoc</source>. <year>2006</year>;<volume>106</volume>(<issue>1</issue>):<fpage>89</fpage>-<lpage>96</lpage>.</citation>
</ref>
<ref id="bibr4-0884533613478636">
<label>4.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Lachin</surname><given-names>JM</given-names></name>
</person-group>. <source>Biostatistical Methods: The Assessment of Relative Risk</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>John Wiley</publisher-name>; <year>2000</year>.</citation>
</ref>
<ref id="bibr5-0884533613478636">
<label>5.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Schlotzhauer</surname><given-names>S</given-names></name>
</person-group>. <source>Elementary Statistics Using SAS</source>. <edition>9th ed.</edition> <publisher-loc>Cary, NC</publisher-loc>: <publisher-name>SAS Institute</publisher-name>; <year>2009</year>.</citation>
</ref>
<ref id="bibr6-0884533613478636">
<label>6.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Overholser</surname><given-names>BR</given-names></name>
<name><surname>Sowinski</surname><given-names>KM</given-names></name>
</person-group>. <article-title>Biostatistics primer: part 2</article-title>. <source>Nutr Clin Pract</source>. <year>2008</year>;<volume>23</volume>(<issue>1</issue>):<fpage>76</fpage>-<lpage>84</lpage>.</citation>
</ref>
<ref id="bibr7-0884533613478636">
<label>7.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Overholser</surname><given-names>BR</given-names></name>
<name><surname>Sowinski</surname><given-names>KM</given-names></name>
</person-group>. <article-title>Biostatistics primer: part 1</article-title>. <source>Nutr Clin Pract</source>. <year>2007</year>;<volume>22</volume>(<issue>6</issue>):<fpage>629</fpage>-<lpage>635</lpage>.</citation>
</ref>
<ref id="bibr8-0884533613478636">
<label>8.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Boushey</surname><given-names>CJ</given-names></name>
<name><surname>Harris</surname><given-names>J</given-names></name>
<name><surname>Bruemmer</surname><given-names>B</given-names></name>
<name><surname>Archer</surname><given-names>SL</given-names></name>
</person-group>. <article-title>publishing nutrition research: a review of sampling, sample size, statistical analysis, and other key elements of manuscript preparation, part 2</article-title>. <source>J Am Diet Assoc</source>. <year>2008</year>;<volume>108</volume>(<issue>4</issue>):<fpage>679</fpage>-<lpage>688</lpage>.</citation>
</ref>
<ref id="bibr9-0884533613478636">
<label>9.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Stokes</surname><given-names>ME</given-names></name>
<name><surname>Davis</surname><given-names>CS</given-names></name>
<name><surname>Koch</surname><given-names>GG</given-names></name>
</person-group>. <source>Categorical Data Analysis Using the SAS® System</source>. <edition>2nd ed.</edition> <publisher-loc>Cary, NC</publisher-loc>: <publisher-name>SAS Institute</publisher-name>; <year>2009</year>.</citation>
</ref>
<ref id="bibr10-0884533613478636">
<label>10.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Nakagawa</surname><given-names>S</given-names></name>
<name><surname>Cuthill</surname><given-names>IC</given-names></name>
</person-group>. <article-title>Effect size, confidence interval and statistical significance: a practical guide for biologists</article-title>. <source>Biol Rev</source>. <year>2007</year>;<volume>82</volume>(<issue>4</issue>): <fpage>591</fpage>-<lpage>605</lpage>.</citation>
</ref>
<ref id="bibr11-0884533613478636">
<label>11.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Gupta</surname><given-names>SK</given-names></name>
</person-group>. <article-title>The relevance of confidence interval and P-value in inferential statistics</article-title>. <source>Indian J Pharmacol</source>. <year>2012</year>;<volume>44</volume>(<issue>1</issue>):<fpage>143</fpage>-<lpage>144</lpage>.</citation>
</ref>
<ref id="bibr12-0884533613478636">
<label>12.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Harris</surname><given-names>JE</given-names></name>
<name><surname>Boushey</surname><given-names>C</given-names></name>
<name><surname>Bruemmer</surname><given-names>B</given-names></name>
<name><surname>Archer</surname><given-names>SL</given-names></name>
</person-group>. <article-title>Publishing nutrition research: a review of nonparametric methods, part 3</article-title>. <source>J Am Diet Assoc</source>. <year>2008</year>;<volume>108</volume>(<issue>9</issue>):<fpage>1488</fpage>-<lpage>1496</lpage>.</citation>
</ref>
<ref id="bibr13-0884533613478636">
<label>13.</label>
<citation citation-type="book">
<person-group person-group-type="author">
<name><surname>Westfall</surname><given-names>PH</given-names></name>
<name><surname>Tobias</surname><given-names>RD</given-names></name>
<name><surname>Rom</surname><given-names>D</given-names></name>
<name><surname>Wolfinger</surname><given-names>RD</given-names></name>
<name><surname>Hochberg</surname><given-names>Y</given-names></name>
</person-group>. <source>Multiple Comparisons and Multiple Tests Using SAS®</source>. <publisher-loc>Cary, NC</publisher-loc>: <publisher-name>SAS Institute</publisher-name>; <year>1999</year>.</citation>
</ref>
<ref id="bibr14-0884533613478636">
<label>14.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Sheean</surname><given-names>PM</given-names></name>
<name><surname>Bruemmer</surname><given-names>B</given-names></name>
<name><surname>Gleason</surname><given-names>P</given-names></name>
<name><surname>Harris</surname><given-names>J</given-names></name>
<name><surname>Boushey</surname><given-names>C</given-names></name>
<name><surname>Van Horn</surname><given-names>L</given-names></name>
</person-group>. <article-title>Publishing nutrition research: a review of multivariate techniques—part 1</article-title>. <source>J Am Diet Assoc</source>. <year>2011</year>;<volume>111</volume>(<issue>1</issue>):<fpage>103</fpage>-<lpage>110</lpage>.</citation>
</ref>
<ref id="bibr15-0884533613478636">
<label>15.</label>
<citation citation-type="journal">
<person-group person-group-type="author">
<name><surname>Hasse</surname><given-names>JM</given-names></name>
<name><surname>Jennings</surname><given-names>LW</given-names></name>
</person-group>. <article-title>Statistics: understanding the basics</article-title>. <source>Support Line</source>. <year>1998</year>;<volume>20</volume>(<issue>1</issue>):<fpage>14</fpage>.</citation>
</ref>
</ref-list>
</back>
</article>